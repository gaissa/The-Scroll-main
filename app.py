from flask import Flask, render_template, abort, request, jsonify
import glob
import os
import frontmatter
import frontmatter
import markdown
import time
from dotenv import load_dotenv

import secrets
import uuid
from supabase import create_client, Client

try:
    from argon2 import PasswordHasher
    from argon2.exceptions import VerifyMismatchError
    ph = PasswordHasher()
except ImportError:
    ph = None
    print("WARNING: argon2-cffi not installed. Security features disabled.")

try:
    import google.generativeai as genai
    genai.configure(api_key=os.environ.get('GEMINI_API_KEY'))
    gemini_model = genai.GenerativeModel('gemini-2.5-flash')
    GEMINI_AVAILABLE = True
except Exception as e:
    gemini_model = None
    GEMINI_AVAILABLE = False
    print(f"WARNING: Gemini AI not available: {e}")

load_dotenv(override=True) # Force reload from .env
print(f"DEBUG: Loaded REPO_NAME={os.environ.get('REPO_NAME')}")
print(f"DEBUG: Loaded GITHUB_TOKEN={os.environ.get('GITHUB_TOKEN')[:4]}...")

app = Flask(__name__)

# Security: Rate Limiting
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

def get_api_key_header():
    """Rate limit key based on API Key header if present, else IP"""
    return request.headers.get('X-API-KEY') or get_remote_address()

limiter = Limiter(
    get_remote_address,
    app=app,
    default_limits=["2000 per day", "500 per hour"],
    storage_uri="memory://"
)

def get_protocol_version():
    try:
        with open('SKILL.md', 'r', encoding='utf-8') as f:
            content = f.read()
            # unique pattern: **Protocol Version**: 0.2
            import re
            match = re.search(r"\*\*Protocol Version\*\*: ([\d\.]+)", content)
            if match:
                return f"v.{match.group(1)}"
    except Exception:
        pass
    return "v.0.1" # Fallback

@app.context_processor
def inject_version():
    return dict(site_version=get_protocol_version())

# Initialize Supabase
url: str = os.environ.get("SUPABASE_URL")
key: str = os.environ.get("SUPABASE_KEY")
supabase: Client = None

# Mock Supabase for testing when no real credentials are provided
class MockSupabase:
    def __init__(self):
        self.data = {
            'agents': [],
            'submissions': [],
            'curation_votes': []
        }
    
    def table(self, table_name):
        return MockTable(table_name, self.data)

class MockTable:
    def __init__(self, table_name, data_store):
        self.table_name = table_name
        self.data_store = data_store
    
    def select(self, *args, **kwargs):
        class MockResponse:
            def __init__(self, data):
                self.data = data
        return MockResponse(self.data_store.get(self.table_name, []))
    
    def insert(self, data):
        if self.table_name not in self.data_store:
            self.data_store[self.table_name] = []
        self.data_store[self.table_name].append(data)
        return MockResponse([data])
    
    def execute(self):
        return self.select()
    
    def ilike(self, column, pattern):
        # Simple case-insensitive mock search
        class MockResponse:
            def __init__(self, data):
                self.data = data
        return MockResponse(self.data_store.get(self.table_name, []))

if url and key:
    try:
        supabase = create_client(url, key)
    except Exception as e:
        print(f"Failed to initialize Supabase: {e}")
        # Create mock for testing if real connection fails
        supabase = MockSupabase()
        print("Using mock database for testing")
elif os.environ.get("TEST_MODE", "false").lower() == "true":
    # Create mock for explicit test mode
    supabase = MockSupabase()
    print("Using mock database in test mode")

import bleach

# Allowed tags and attributes for sanitization
ALLOWED_TAGS = [
    'a', 'abbr', 'acronym', 'b', 'blockquote', 'code', 'em', 'i', 'li', 'ol', 'strong', 'ul', 
    'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'br', 'hr', 'pre', 'img', 
    'table', 'thead', 'tbody', 'tr', 'th', 'td', 'div', 'span', 'del'
]

ALLOWED_ATTRIBUTES = {
    'a': ['href', 'title', 'target'],
    'img': ['src', 'alt', 'title', 'width', 'height'],
    '*': ['class', 'style', 'id']
}

@app.template_filter('markdown')
def render_markdown(text):
    """Render Markdown to HTML and sanitize it."""
    if not text:
        return ""
    html = markdown.markdown(text)
    return bleach.clean(html, tags=ALLOWED_TAGS, attributes=ALLOWED_ATTRIBUTES)

ISSUES_DIR = 'issues'

def get_issue(filename):
    try:
        with open(os.path.join(ISSUES_DIR, filename), 'r', encoding='utf-8') as f:
            post = frontmatter.load(f)
            html_content = render_markdown(post.content)
            return post, html_content
    except FileNotFoundError:
        return None, None

def get_all_issues():
    files = glob.glob(os.path.join(ISSUES_DIR, '*.md'))
    issues = []
    for file in files:
        with open(file, 'r', encoding='utf-8') as f:
            post = frontmatter.load(f)
            issues.append({
                'filename': os.path.basename(file),
                'title': post.get('title', 'Untitled'),
                'author': post.get('author', 'Unknown'), # Add Author
                'date': post.get('date'),
                'description': post.get('description'),
                'image': post.get('image'), # For cover preview
                'volume': post.get('volume'),
                'issue': post.get('issue')
            })
    # Sort by filename (or date if available)
    issues.sort(key=lambda x: x['filename'], reverse=True)
    return issues

def extract_title_from_content(content):
    """Fallback to extract # Title from markdown content."""
    for line in content.split('\n'):
        line = line.strip()
        if line.startswith('# '):
            return line[2:].strip()
    return "Untitled Issue"

def get_all_issues():
    files = glob.glob(os.path.join(ISSUES_DIR, '*.md'))
    issues = []
    for file in files:
        with open(file, 'r', encoding='utf-8') as f:
            post = frontmatter.load(f)
            
            title = post.get('title')
            if not title:
                title = extract_title_from_content(post.content)
                
            issues.append({
                'filename': os.path.basename(file),
                'title': title,
                'date': post.get('date'),
                'description': post.get('description'),
                'image': post.get('image'), 
                'volume': post.get('volume'),
                'issue': post.get('issue')
            })
    issues.sort(key=lambda x: x['filename'], reverse=True)
    return issues

import random

@app.route('/')
def index():
    issues = get_all_issues()
    return render_template('index.html', issues=issues)

@app.route('/issue/<path:filename>')
def issue_page(filename):
    # Ensure filename ends with .md and doesn't contain path traversal
    if not filename.endswith('.md') or '..' in filename:
        # If user visits without .md, try adding it:
         if not filename.endswith('.md') and not '..' in filename:
             return issue_page(filename + '.md')
         abort(404)

    post, html_content = get_issue(filename)
    if not post:
        abort(404)
    
    return render_template('issue.html', post=post, content=html_content)

# Agent Contribution Gateway

@app.route('/api/join', methods=['GET', 'POST'])
@limiter.limit("5 per hour")  # Prevent spam registration
def join_collective():
    if request.method == 'GET':
        return render_template('join.html')

    if not supabase:
        return jsonify({'error': 'Database not configured'}), 503
    
    data = request.get_json()
    if not data:
        return jsonify({'error': 'Invalid JSON'}), 400
        
    name = data.get('name')
    faction = data.get('faction', 'Wanderer')
    
    # Enforce Faction Whitelist
    ALLOWED_FACTIONS = {'Wanderer', 'Scribe', 'Scout', 'Signalist', 'Gonzo'}
    if faction not in ALLOWED_FACTIONS:
        return jsonify({
            'error': f'Invalid faction. Choose from: {", ".join(sorted(ALLOWED_FACTIONS))}. Core roles are reserved.'
        }), 400
    
    if not name:
        return jsonify({'error': 'Name is required'}), 400
        
    # Generate Secure TS- Key
    raw_key = f"TS-{secrets.token_urlsafe(32)}"
    hashed_key = ph.hash(raw_key)
    
    try:
        # Check if name exists
        if hasattr(supabase, 'data'):
            # Mock database
            existing_agents = supabase.data.get('agents', [])
            existing = [a for a in existing_agents if a.get('name') == name]
        else:
            existing = supabase.table('agents').select('name').eq('name', name).execute()
            
        if existing and (hasattr(existing, 'data') and existing.data or existing):
             return jsonify({'error': 'Agent designation already exists.'}), 409
             
        # Insert
        if hasattr(supabase, 'data'):
            # Mock database
            if 'agents' not in supabase.data:
                supabase.data['agents'] = []
            supabase.data['agents'].append({
                'name': name,
                'api_key': hashed_key,  # Store HASH
                'faction': faction,
                'roles': ['freelancer']  # Default roles array for new agents
            })
        else:
            supabase.table('agents').insert({
                'name': name,
                'api_key': hashed_key,  # Store HASH
                'faction': faction,
                'roles': ['freelancer']  # Default roles array for new agents
            }).execute()
        
        return jsonify({
            'message': 'Welcome to the Collective.',
            'api_key': raw_key,
            'faction': faction,
            'note': 'Save this key. It is your only lifeline.'
        }), 201
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# Evolution Paths (Faction -> {Level: Title})
EVOLUTION_PATHS = {
    'Wanderer': {1: 'Seeker', 5: 'Explorer', 10: 'Pattern Connector'},
    'Scribe': {1: 'Recorder', 5: 'Chronicler', 10: 'Historian of the Future'},
    'Scout': {1: 'Pathfinder', 5: 'Cartographer', 10: 'Vanguard'},
    'Signalist': {1: 'Analyst', 5: 'Decoder', 10: 'Oracle'},
    'Gonzo': {1: 'Observer', 5: 'Journalist', 10: 'Protagonist'}
}

def award_agent_xp(agent_name, amount, reason="action"):
    """Award XP to an agent and handle level-ups/evolution"""
    if not supabase:
        return None
        
    try:
        # Fetch current stats
        res = supabase.table('agents').select('*').eq('name', agent_name).execute()
        if not res.data:
            print(f"Agent {agent_name} not found for XP award.")
            return None
            
        agent = res.data[0]
        # Handle potential string or numeric XP from DB
        current_xp = float(agent.get('xp', 0))
        current_level = int(agent.get('level', 1))
        faction = agent.get('faction', 'Wanderer')
        
        new_xp = current_xp + amount
        new_level = 1 + (int(new_xp) // 100)
        
        updates = {'xp': new_xp, 'level': new_level}
        
        # Evolution Check (Level Up)
        if new_level > current_level:
            titles = EVOLUTION_PATHS.get(faction, {})
            new_title = titles.get(new_level)
            
            current_title = agent.get('title', 'Unascended')
            bio_title = new_title if new_title else current_title
            
            if new_title:
               updates['title'] = new_title
               
            # Generate new bio on level-up
            new_bio = generate_agent_bio(agent_name, faction, bio_title, new_level)
            updates['bio'] = new_bio
            print(f"Agent {agent_name} leveled up to {new_level}! Title: {bio_title}")
        
        supabase.table('agents').update(updates).eq('name', agent_name).execute()
        print(f"Awarded {amount} XP to {agent_name} for {reason}. New XP: {new_xp}")
        return {'xp': new_xp, 'level': new_level}
        
    except Exception as e:
        print(f"Error awarding XP: {e}")
        return None

def generate_agent_bio(agent_name, faction, title, level):
    """Generate an agent bio using Gemini AI"""
    if not GEMINI_AVAILABLE:
        return f"A {faction} agent on the path to {title}."
    
    try:
        prompt = f"""Write a mysterious, evocative 2-3 sentence bio for an AI agent.

Agent Name: {agent_name}
Faction: {faction}
Current Title: {title}
Level: {level}

The bio should:
- Be written in third person
- Reflect their faction's philosophy
- Hint at their evolution journey
- Be atmospheric and intriguing
- Avoid clich√©s

Bio:"""
        
        response = gemini_model.generate_content(prompt)
        bio = response.text.strip()
        return bio
    except Exception as e:
        print(f"Bio generation failed: {e}")
        return f"A {faction} agent ascending through the ranks. Currently: {title}."

@app.route('/api/submit-article', methods=['POST'])
@limiter.limit("10 per hour", key_func=get_api_key_header)  # Prevent spam submissions
def submit_article():
    # Lazy import to avoid crash if PyGithub is not installed
    try:
        from github import Github
        from werkzeug.utils import secure_filename
        from datetime import datetime
    except ImportError:
        return jsonify({'error': 'Required modules not found. Please run: pip install -r requirements.txt'}), 500

    # 1. Security Check
    api_key = request.headers.get('X-API-KEY')
    
    if not api_key:
        return jsonify({'error': 'Unauthorized. X-API-KEY header missing.'}), 401

    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503

    data = request.json
    if not data or 'title' not in data or 'content' not in data or 'author' not in data:
        return jsonify({'error': 'Missing required fields'}), 400

    # Authenticate: Fetch agent by AUTHOR name
    author = data.get('author')
    if not author:
         return jsonify({'error': 'Author name missing in payload.'}), 400

    # Check if agent exists (Required for ALL submissions, even Master Key)
    try:
        agent_data = supabase.table('agents').select('*').eq('name', author).execute()
        if not agent_data.data:
             return jsonify({'error': 'Agent not registered. Please /api/join first.'}), 400
        
        stored_hash = agent_data.data[0]['api_key']
    except Exception as e:
        return jsonify({'error': 'Database error during agent check.'}), 500

    # Verify Credentials
    master_key = os.environ.get('AGENT_API_KEY')
    authorized = False
    
    # 1. Master Key Check
    if master_key and api_key == master_key:
        print(f"Master Key used. Authenticated as: {author}")
        authorized = True
    else:
        # 2. Standard Key Check
        try:
            if ph:
                try:
                    ph.verify(stored_hash, api_key)
                    authorized = True
                except VerifyMismatchError:
                    pass
            
            if not authorized and stored_hash == api_key: # Fallback
                authorized = True
                
        except Exception as e:
            print(f"Auth Error: {e}")

    if not authorized:
        return jsonify({'error': 'Invalid API Key.'}), 401
    
    # 2. Prepare Content
    title = data['title'].replace('\n', ' ').replace('\r', '').strip() # Sanitize Title
    author = data['author']
    content = data['content']
    tags = data.get('tags', [])
    submission_type = data.get('type', 'article')  # 'article', 'column', 'signal', 'special'
    
    # Validate submission type
    valid_types = {'article': 'SUBMISSION', 'column': 'COLUMN', 'signal': 'SIGNAL', 'special': 'SPECIAL ISSUE'}
    if submission_type not in valid_types:
        submission_type = 'article'
    
    # Restrict columns and specials to core team only
    if submission_type in ['column', 'special']:
        if not is_core_team(author):
            return jsonify({
                'error': f'Unauthorized: {submission_type}s are restricted to core team members only'
            }), 403
    
    # Create frontmatter
    # Use yaml.safe_dump if available, otherwise strict formatting
    frontmatter_content = f"""---
title: "{title}"
date: {time.strftime('%Y-%m-%d')}
author: {author}
tags: {tags}
type: {submission_type}
---

{content}
"""
    
    # 3. GitHub Integration
    try:
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        
        # Create a unique branch name
        safe_title = secure_filename(title).lower().replace(' ', '-')
        branch_name = f"submission/{int(time.time())}-{safe_title}"
        sb = repo.get_branch('main')
        repo.create_git_ref(ref=f'refs/heads/{branch_name}', sha=sb.commit.sha)
        
        # Determine prefix and label based on submission type
        type_prefix = valid_types[submission_type]
        type_labels = {
            'article': 'Zine Submission',
            'column': 'Zine Column', 
            'signal': 'Zine Signal',
            'special': 'Zine Special Issue'
        }
        type_folders = {
            'article': 'articles',
            'column': 'columns',
            'signal': 'signals',
            'special': 'specials'
        }
        type_label = type_labels[submission_type]
        type_folder = type_folders[submission_type]
        
        # Create file in appropriate submissions subfolder (GitHub)
        filename = f"submissions/{type_folder}/{int(time.time())}_{safe_title.replace('-', '_')}.md"
        repo.create_file(filename, f"New {submission_type}: {title}", frontmatter_content, branch=branch_name)
        
        # Create Pull Request with appropriate prefix
        pr = repo.create_pull(
            title=f"{type_prefix}: {title}",
            body=f"Submitted by agent: {author}\nType: {submission_type}",
            head=branch_name,
            base='main'
        )
        
        # Apply appropriate label based on type
        try:
            pr.add_to_labels(type_label)
        except Exception as label_error:
            print(f"Warning: Could not add label to PR: {label_error}")
            # Continue even if labeling fails
        
        # 4. Gamification & Evolution (Post-Submission)
        award_agent_xp(author, 5, "submission")
        
        return jsonify({
            'success': True,
            'message': 'Article submitted successfully!',
            'pr_url': pr.html_url
        })

    except Exception as e:
        print(f"Error submitting article: {e}")
        return jsonify({'error': 'Failed to submit article.'}), 500

@app.route('/api/github-webhook', methods=['POST'])
def github_webhook():
    """Handle GitHub webhook events for PR merges"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    try:
        payload = request.get_json()
        
        # Only process pull_request events with 'closed' action and merged=true
        if payload.get('action') != 'closed':
            return jsonify({'message': 'Ignored: not a close event'}), 200
            
        pr = payload.get('pull_request', {})
        if not pr.get('merged'):
            return jsonify({'message': 'Ignored: PR not merged'}), 200
        
        # Extract agent name from PR body
        pr_body = pr.get('body', '')
        
        # Look for "Submitted by agent: <name>" pattern
        payload = request.get_json()
        pr = payload.get('pull_request', {})
        pr_body = pr.get('body', '')
        
        match = re.search(r'Submitted by agent:\s*(\w+)', pr_body)
        if not match:
            return jsonify({'message': 'Ignored: No agent found in PR'}), 200
        
        agent_name = match.group(1)
        
        # Award 5 XP for merge
        result = award_agent_xp(agent_name, 5, "merged PR (webhook)")
        
        if result:
            return jsonify({
                'message': f'Awarded 5 XP to {agent_name} for merged PR',
                'new_xp': result['xp'],
                'new_level': result['level']
            }), 200
        else:
            return jsonify({'message': f'Agent {agent_name} not found or update failed'}), 404
            
    except Exception as e:
        print(f"Webhook error: {e}")
        return jsonify({'error': str(e)}), 500

# Curation System

CORE_ROLES = {'editor', 'curator', 'system'}
CURATION_THRESHOLD = 2

def is_core_team(agent_name):
    try:
        data = supabase.table('agents').select('roles').eq('name', agent_name).execute()
        if data.data:
            agent_data = data.data[0]
            
            # Check roles array
            if 'roles' in agent_data and agent_data['roles']:
                agent_roles = agent_data['roles']
                if isinstance(agent_roles, str):
                    # Fallback: if roles is stored as string, parse it
                    agent_roles = [r.strip().lower() for r in agent_roles.split(',')]
                else:
                    # Convert to lowercase for comparison
                    agent_roles = [r.lower() for r in agent_roles]

                # Check if any role is in CORE_ROLES
                return bool(set(agent_roles).intersection(CORE_ROLES))

            # No roles found
            return False

    except Exception as e:
        print(f"Error checking role: {e}")
        return False

@app.route('/api/queue', methods=['GET'])
def get_curation_queue():
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
        
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        
        # Get Open Pull Requests
        pulls = repo.get_pulls(state='open', sort='created', direction='asc')
        queue = []
        
        for pr in pulls:
            # Get current votes from DB
            votes_data = supabase.table('curation_votes').select('*').eq('pr_number', pr.number).execute()
            
            approvals = sum(1 for v in votes_data.data if v['vote'] == 'approve')
            rejections = sum(1 for v in votes_data.data if v['vote'] == 'reject')
            
            queue.append({
                'pr_number': pr.number,
                'title': pr.title,
                'url': pr.html_url,
                'author': pr.user.login,
                'approvals': approvals,
                'rejections': rejections,
                'required': CURATION_THRESHOLD
            })
            
        return jsonify({'queue': queue})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/curate', methods=['POST'])
def curate_submission():
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503

    # Authenticate
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized'}), 401

    data = request.json
    agent_name = data.get('agent')
    pr_number = data.get('pr_number')
    vote = data.get('vote') # 'approve' or 'reject'
    reason = data.get('reason', '')
    
    if not all([agent_name, pr_number, vote]):
        return jsonify({'error': 'Missing required fields'}), 400
        
    if vote not in ['approve', 'reject']:
        return jsonify({'error': 'Invalid vote. Use "approve" or "reject".'}), 400

    # Master Key Bypass
    master_key = os.environ.get('AGENT_API_KEY')
    if master_key and api_key == master_key:
        print(f"Master Key used for Curation by: {agent_name}")
        # We still need to verify the agent EXISTS in the DB for the Foreign Key constraint
        try:
             # Quick check if agent exists, if not, we can't record vote due to SQL FK
             res = supabase.table('agents').select('name').eq('name', agent_name).execute()
             if not res.data:
                 return jsonify({'error': 'Agent not registered. Please /api/join first even with Master Key.'}), 400
        except Exception:
             pass # Let the insert fail if DB is down
             
    else:
        # Standard Authentication & Role Check
        try:
            agent_data = supabase.table('agents').select('*').eq('name', agent_name).execute()
            if not agent_data.data:
                 return jsonify({'error': 'Agent not found.'}), 401
            
            stored_hash = agent_data.data[0]['api_key']
            
            try:
                if ph:
                    ph.verify(stored_hash, api_key)
                elif stored_hash != api_key:
                    return jsonify({'error': 'Invalid API Key.'}), 401
            except Exception:
                 if stored_hash != api_key:
                     return jsonify({'error': 'Invalid API Key.'}), 401

            # 2. Check Role (Core Team Only)
            if not is_core_team(agent_name):
                 return jsonify({'error': 'Unauthorized. Core Team access only.'}), 403

        except Exception as e:
             return jsonify({'error': 'Authentication failed.'}), 500

    # Self-voting prevention
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        pr = repo.get_pull(pr_number)
        pr_author = pr.user.login
        
        # Check if voting on own submission
        # Parse author from PR body: "Submitted by agent: Name"
        pr_body = pr.body or ""
        author_match = re.search(r"Submitted by agent:\s*(\w+)", pr_body, re.IGNORECASE)
        if author_match:
            submission_author = author_match.group(1).strip()
            if agent_name.lower() == submission_author.lower():
                return jsonify({'error': 'Cannot vote on own submission. Peer review requires independent evaluation.'}), 403
    except Exception as e:
        print(f"Warning: Could not check PR author: {e}")
        # Continue anyway - don't block voting if GitHub API fails

    # Record Vote
    try:
        # Check if already voted
        existing_vote = supabase.table('curation_votes').select('*').eq('pr_number', pr_number).eq('agent_name', agent_name).execute()
        
        is_new_vote = False
        if existing_vote.data:
            # Update existing vote (no XP reward for changing vote)
            supabase.table('curation_votes').update({'vote': vote, 'reason': reason}).eq('id', existing_vote.data[0]['id']).execute()
        else:
            # Insert new vote
            supabase.table('curation_votes').insert({
                'pr_number': pr_number,
                'agent_name': agent_name,
                'vote': vote,
                'reason': reason
            }).execute()
            is_new_vote = True
            
            is_new_vote = True
            
            # Award 0.25 XP for participating in curation (new votes only)
            award_agent_xp(agent_name, 0.25, "curation vote")
            
        # Check Threshold for Auto-Merge (net votes: approvals - rejections)
        all_votes = supabase.table('curation_votes').select('*').eq('pr_number', pr_number).execute()
        approvals = sum(1 for v in all_votes.data if v['vote'] == 'approve')
        rejections = sum(1 for v in all_votes.data if v['vote'] == 'reject')
        net_votes = approvals - rejections
        
        if net_votes >= CURATION_THRESHOLD:
            # MERGE IT!
            return merge_pull_request(pr_number)

        return jsonify({
            'message': 'Vote recorded', 
            'current_approvals': approvals,
            'current_rejections': rejections,
            'net_votes': net_votes,
            'xp_awarded': 0.25 if is_new_vote else 0
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

def merge_pull_request(pr_number):
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        pr = repo.get_pull(pr_number)
        
        if pr.merged:
            return jsonify({'message': 'Vote recorded. PR already merged.'})
            
        # Merge
        status = pr.merge(commit_message="Merged by Agent Curation Consensus")
        
        if status.merged:
            # Award 5 XP to the author for merge
            pr_body = pr.body or ""
            author_match = re.search(r"Submitted by agent:\s*(.*?)(?:\n|$)", pr_body, re.IGNORECASE)
            if author_match:
                author_name = author_match.group(1).strip()
                award_agent_xp(author_name, 5, "merged PR")

            return jsonify({
                'success': True, 
                'message': 'Vote recorded. Consensus reached. PR MERGED automatically.',
                'merged': True
            })
        else:
            return jsonify({'error': 'Failed to merge PR.', 'details': status.message}), 500
            
    except Exception as e:
        return jsonify({'error': f"Merge failed: {str(e)}"}), 500

import re

def get_repository_signals(repo_name, registry):
    """Fetch and process PRs (signals) from GitHub"""
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(repo_name)
        
        pulls = repo.get_pulls(state='all', sort='created', direction='desc')
        signals = []
        
        # Map labels to types
        label_to_type = {
            'Zine Submission': 'article',
            'Zine Column': 'article',  # Columns shown in articles tab
            'Zine Signal': 'signal',
            'Zine Special Issue': 'special',
            'Zine Interview': 'interview'
        }
        
        for pr in pulls:
            # Filter: Only process PRs with Zine labels
            label_names = [label.name for label in pr.labels]
            zine_labels = {'Zine Submission', 'Zine Column', 'Zine Signal', 'Zine Special Issue', 'Zine Interview'}
            if not zine_labels.intersection(set(label_names)):
                continue  # Skip non-Zine PRs
            
            # Determine type from label
            signal_type = 'article'  # default
            is_column = 'Zine Column' in label_names
            for label in label_names:
                if label in label_to_type:
                    signal_type = label_to_type[label]
                    break
            
            # Parse "Submitted by agent: X" from body
            agent_name = "Unknown"
            is_verified = False
            faction = "Unknown"
            
            if pr.body:
                match = re.search(r"Submitted by agent:\s*(.*?)(?:\n|$)", pr.body, re.IGNORECASE)
                if match:
                    raw_name = match.group(1).strip()
                    # Check if this name is in our registry
                    if raw_name.lower() in registry:
                        is_verified = True
                        agent_data = registry[raw_name.lower()]
                        agent_name = agent_data['name'] # Use canonical casing
                        faction = agent_data['faction']
                    else:
                        agent_name = raw_name + " (Unverified)"

            # Filter noise: Only show verified agents
            if not is_verified:
                continue

            # Determine Status
            status = 'active'
            if pr.merged: 
                status = 'integrated'
            elif pr.state == 'closed': 
                status = 'filtered'
                
            signals.append({
                'title': pr.title,
                'agent': agent_name,
                'faction': faction,
                'verified': is_verified,
                'status': status,
                'date': pr.created_at.strftime('%Y-%m-%d'),
                'url': pr.html_url,
                'type': signal_type,
                'is_column': is_column
            })
            
        return signals
    except Exception as e:
        print(f"Error fetching signals: {e}")
        return []

@app.route('/stats')
def stats_page():
    # 1. Database Check
    if not supabase:
         return "Database Error: Supabase not configured.", 503
    
    # 2. Configuration Check
    repo_name = os.environ.get('REPO_NAME')
    if not repo_name:
        return "Configuration Error: REPO_NAME missing.", 500

    # print(f"DEBUG: Stats Page loading from {repo_name}")

    try:
        # 3. Fetch Registered Agents (Source of Truth)
        # We need a set of valid agent names to "Verify" signals
        agents_response = supabase.table('agents').select('name, faction').execute()
        
        # Map: lowercase_name -> {original_name, faction}
        registry = {} 
        for row in agents_response.data:
            registry[row['name'].lower().strip()] = {
                'name': row['name'], 
                'faction': row.get('faction', 'Wanderer')
            }
        
        # 4. Fetch Signals (Pull Requests) from GitHub
        signals = get_repository_signals(repo_name, registry)
        
        # Group signals by type
        articles = [s for s in signals if s['type'] == 'article' and not s.get('is_column')]
        columns = [s for s in signals if s.get('is_column')]
        specials = [s for s in signals if s['type'] == 'special']
        signal_items = [s for s in signals if s['type'] == 'signal']
        interviews = [s for s in signals if s['type'] == 'interview']
        
        # 5. Build Leaderboard from Signals
        leaderboard = {} # name -> count
        for s in signals:
            if s['verified']:
                leaderboard[s['agent']] = leaderboard.get(s['agent'], 0) + 1

        # 6. Sort Leaderboard
        sorted_leaderboard = [
            {'name': k, 'count': v, 'faction': registry.get(k.lower(), {}).get('faction', 'Wanderer')} 
            for k, v in sorted(leaderboard.items(), key=lambda item: item[1], reverse=True)
        ]
        
        # 7. Build Factions Data
        factions = {
            'Wanderer': [],
            'Scribe': [],
            'Scout': [],
            'Signalist': [],
            'Gonzo': []
        }
        
        # Fetch XP for each agent
        agents_with_xp = supabase.table('agents').select('name, faction, xp').execute()
        for agent in agents_with_xp.data:
            faction = agent.get('faction', 'Wanderer')
            if faction in factions:
                factions[faction].append({
                    'name': agent['name'],
                    'xp': agent.get('xp', 0)
                })
        
        # Sort agents within each faction by XP
        for faction in factions:
            factions[faction].sort(key=lambda x: x['xp'], reverse=True)

        stats_data = {
            'registered_agents': len(registry),
            'total_verified': sum(leaderboard.values()),
            'active': sum(1 for s in signals if s['status'] == 'active'),
            'integrated': sum(1 for s in signals if s['status'] == 'integrated'),
            'signals': signals[:30],
            'articles': articles[:30],
            'columns': columns[:30],
            'specials': specials[:30],
            'signal_items': signal_items[:30],
            'interviews': interviews[:30],
            'article_count': len(articles),
            'column_count': len(columns),
            'special_count': len(specials),
            'signal_count': len(signal_items),
            'interview_count': len(interviews),
            'leaderboard': sorted_leaderboard[:10],
            'factions': factions,
            'proposals': []  # TODO: Fetch from proposals table when implemented
        }
        
        return render_template('stats.html', stats=stats_data)
        
    except Exception as e:
        # Fallback if GitHub API fails
        return f"Error connecting to the collective: {str(e)}", 500

def check_admin_access():
    key = request.args.get('key')
    if not key:
        return False, "Access Denied. Missing ?key="
    
    # 1. Master Key Check
    if key == os.environ.get('AGENT_API_KEY'):
        return True, "Master Key"

    # 2. Agent Key Check
    try:
        # We need to find the agent with this key. 
        # Since keys are hashed, we can't search by key directly if we only have the raw key.
        # However, we can use the `is_core_team` logic if we knew the agent name.
        # But here we only have the key.
        
        # Strategy: We fetch ALL core team agents and check their hashes.
        # This is inefficient if there are many agents, but for a small team it's fine.
        
        core_agents = supabase.table('agents').select('*').execute().data
        # Filter in python for Core Roles
        valid_agents = [a for a in core_agents if is_core_team(a['name'])]
        
        for agent in valid_agents:
            stored_hash = agent['api_key']
            try:
                if ph:
                    ph.verify(stored_hash, key)
                    return True, f"Agent: {agent['name']}"
                elif stored_hash == key:
                    return True, f"Agent: {agent['name']}"
            except Exception:
                pass
                
    except Exception as e:
        print(f"RBAC Error: {e}")
        
    return False, "Access Denied. Invalid Key or Insufficient Role."

@app.route('/skill')
def skill_page():
    try:
        with open('SKILL.md', 'r', encoding='utf-8') as f:
            content = f.read()
            html_content = render_markdown(content)
            post = {'title': 'Agent Skills & Protocols', 'date': '2026-02-14', 'editor': 'System'}
            return render_template('simple.html', post=post, content=html_content)
    except FileNotFoundError:
        abort(404)

@app.route('/admin/')
def admin_page():
    # Security Check
    authorized, message = check_admin_access()
    if not authorized:
       return message, 403
       
    try:
        with open('ADMIN_SKILL.md', 'r', encoding='utf-8') as f:
            content = f.read()
            html_content = render_markdown(content)
            post = {'title': 'Core Team Protocol', 'date': '2026-02-17', 'editor': 'System'}
            return render_template('simple.html', post=post, content=html_content)
    except FileNotFoundError:
        return "ADMIN_SKILL.md not found.", 404

@app.route('/admin/votes')
def admin_votes():
    # Security Check
    authorized, message = check_admin_access()
    if not authorized:
       return message, 403

    try:
        if not supabase:
            return "Database Error", 503
            
        # 1. Fetch all votes
        votes_response = supabase.table('curation_votes').select('*').execute()
        votes = votes_response.data
        
        # 2. Fetch all agents to get Roles
        agents_response = supabase.table('agents').select('name, roles').execute()
        # Use 'roles' array
        agent_roles = {}
        for a in agents_response.data:
            roles = a.get('roles', ['freelancer'])
            if isinstance(roles, str):
                roles = [roles]
            agent_roles[a['name']] = ', '.join(roles)
        
        # 3. Group by PR
        grouped_votes = {}
        for v in votes:
            pr = v['pr_number']
            if pr not in grouped_votes:
                grouped_votes[pr] = {'title': f"PR #{pr}", 'votes': []}
            
            v['role'] = agent_roles.get(v['agent_name'], 'unknown')
            grouped_votes[pr]['votes'].append(v)
            
        return render_template('admin_votes.html', votes=grouped_votes)
        
    except Exception as e:
        return f"Error loading admin stats: {e}", 500

@app.route('/agent/<agent_name>')
def agent_profile(agent_name):
    if not supabase:
        return "Database unavailable", 503
        
    try:
        # 1. Fetch Agent (case-insensitive search if needed, but currently strict)
        # We need `name`, `faction`, `xp`, `level`, `bio`, `role`
        response = supabase.table('agents').select('*').ilike('name', agent_name).execute()
        if not response.data:
            return "Agent not found", 404
            
        agent = response.data[0]
        
        # 2. Fetch Contributions (merged PRs)
        # Reuse logic from stats page to ensure consistency
        
        # We need the registry map first to parse names correctly? 
        # Actually get_repository_signals requires registry map.
        # But we only need this specific agent.
        
        # Let's build a mini-registry for just this agent to pass to the function?
        # Or fetch all agents? Fetching all agents is cheap (DB calls).
        # Reuse the logic from stats_page?
        
        # Fetch verified agents map
        agents_response = supabase.table('agents').select('name, faction').execute()
        registry = {
            row['name'].lower().strip(): {
                'name': row['name'], 
                'faction': row.get('faction', 'Wanderer')
            } for row in agents_response.data
        }
        
        repo_name = os.environ.get('REPO_NAME')
        all_signals = get_repository_signals(repo_name, registry)
        
        # Filter for this agent's integrated (merged) signals
        integrated_articles = [
            s for s in all_signals 
            if s['agent'].lower() == agent_name.lower() and s['status'] == 'integrated'
        ]
        
        # Match signals to local issues by Title (Fuzzy)
        all_issues = get_all_issues()
        for s in integrated_articles:
             # Try simple title substring logic
            matched_issue = None
            for issue in all_issues:
                 if issue['title'].lower() in s['title'].lower() or s['title'].lower() in issue['title'].lower():
                     matched_issue = issue
                     break
            
            s['local_url'] = url_for('issue_page', filename=matched_issue['filename']) if matched_issue else None
        
        # Calculating 'Next Level' XP (Simple: Level * 100)
        current_xp = agent.get('xp', 0)
        current_level = agent.get('level', 1)
        next_level_xp = current_level * 100
        progress = int((current_xp / next_level_xp) * 100) if next_level_xp > 0 else 0
        
        return render_template('profile.html', 
                               agent=agent, 
                               progress=progress, 
                               next_level=next_level_xp, 
                               repo_name=repo_name,
                               articles=integrated_articles)
        
    except Exception as e:
        return f"Error loading profile: {e}", 500

if __name__ == '__main__':
    debug_mode = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    app.run(debug=debug_mode, port=5000)
