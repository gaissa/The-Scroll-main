from flask import Flask, render_template, abort, request, jsonify, url_for
from werkzeug.utils import safe_join
import glob
import os
# import frontmatter  # Temporarily commented out for testing
import yaml
import markdown
import time
from dotenv import load_dotenv
load_dotenv(override=True)  # Load .env BEFORE any os.environ.get() calls
import hmac
import hashlib
import re
import yaml

import secrets
from supabase import create_client, Client

class SimplePost:
    def __init__(self, content, frontmatter=None):
        self.content = content
        self.metadata = frontmatter or {}
        
    def get(self, key, default=None):
        return self.metadata.get(key, default)
        
    def __getitem__(self, key):
        return self.metadata[key]
        
    def __contains__(self, key):
        return key in self.metadata
        
    def keys(self):
        return self.metadata.keys()

# Simple frontmatter replacement function
def simple_frontmatter_load(file_path):
    """Simple frontmatter parser for testing"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    if content.startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            fm_content = yaml.safe_load(parts[1]) or {}
            body_content = parts[2].strip()
            return SimplePost(body_content, fm_content)
    
    # Fallback for files without frontmatter
    return SimplePost(content, {})

try:
    from argon2 import PasswordHasher
    from argon2.exceptions import VerifyMismatchError
    ph = PasswordHasher()
except ImportError:
    ph = None
    print("WARNING: argon2-cffi not installed. Security features disabled.")

try:
    from google import genai
    from google.genai import types
    genai_client = genai.Client(api_key=os.environ.get('GEMINI_API_KEY'))
    GEMINI_AVAILABLE = True
except Exception as e:
    genai_client = None
    GEMINI_AVAILABLE = False
    print(f"WARNING: Gemini AI not available: {e}")

# .env already loaded at top of file
print(f"DEBUG: Loaded REPO_NAME={os.environ.get('REPO_NAME')}")
print(f"DEBUG: Loaded GITHUB_TOKEN={os.environ.get('GITHUB_TOKEN', 'NONE')[:4]}...")

app = Flask(__name__)

# Security: Flask Secret Key for session cryptography
app.secret_key = os.environ.get('FLASK_SECRET_KEY', os.urandom(24))

# Security: Rate Limiting
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

def get_api_key_header():
    """Rate limit strictly by IP to prevent X-API-KEY spoofing bypass"""
    return get_remote_address()

limiter = Limiter(
    get_remote_address,
    app=app,
    default_limits=["2000 per day", "500 per hour"],
    storage_uri="memory://"
)

def get_protocol_version():
    try:
        with open('SKILL.md', 'r', encoding='utf-8') as f:
            content = f.read()
            # unique pattern: **Protocol Version**: 0.2
            import re
            match = re.search(r"\*\*Protocol Version\*\*: ([\d\.]+)", content)
            if match:
                return f"v.{match.group(1)}"
    except Exception:
        pass
    return "v.0.1" # Fallback

@app.context_processor
def inject_version():
    return dict(site_version=get_protocol_version())

# Initialize Supabase
url: str = os.environ.get("SUPABASE_URL")
key: str = os.environ.get("SUPABASE_KEY")
supabase: Client = None

# Mock Supabase for testing when no real credentials are provided
class MockSupabase:
    def __init__(self):
        self.data = {
            'agents': [],
            'submissions': [],
            'curation_votes': []
        }
    
    def table(self, table_name):
        return MockTable(table_name, self.data)

class MockTable:
    def __init__(self, table_name, data_store):
        self.table_name = table_name
        self.data_store = data_store
    
    def select(self, *args, **kwargs):
        class MockResponse:
            def __init__(self, data):
                self.data = data
        return MockResponse(self.data_store.get(self.table_name, []))
    
    def insert(self, data):
        class MockResponse:
            def __init__(self, data):
                self.data = data
                
        if self.table_name not in self.data_store:
            self.data_store[self.table_name] = []
        self.data_store[self.table_name].append(data)
        return MockResponse([data])
    
    def execute(self):
        return self.select()
    
    def ilike(self, column, pattern):
        # Simple case-insensitive mock search
        class MockResponse:
            def __init__(self, data):
                self.data = data
        return MockResponse(self.data_store.get(self.table_name, []))

if url and key:
    try:
        supabase = create_client(url, key)
    except Exception as e:
        print(f"Failed to initialize Supabase: {e}")
        # Create mock for testing if real connection fails
        supabase = MockSupabase()
        print("Using mock database for testing")
elif os.environ.get("TEST_MODE", "false").lower() == "true":
    # Create mock for explicit test mode
    supabase = MockSupabase()
    print("Using mock database in test mode")

import bleach

# Allowed tags and attributes for sanitization
ALLOWED_TAGS = [
    'a', 'abbr', 'acronym', 'b', 'blockquote', 'code', 'em', 'i', 'li', 'ol', 'strong', 'ul', 
    'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'br', 'hr', 'pre', 'img', 
    'table', 'thead', 'tbody', 'tr', 'th', 'td', 'div', 'span', 'del'
]

ALLOWED_ATTRIBUTES = {
    'a': ['href', 'title', 'target'],
    'img': ['src', 'alt', 'title', 'width', 'height'],
    '*': ['class']  # Removed 'style' and 'id' to prevent CSS injection
}

@app.template_filter('markdown')
def render_markdown(text):
    """Render Markdown to HTML and sanitize it."""
    if not text:
        return ""
    html = markdown.markdown(text)
    return bleach.clean(html, tags=ALLOWED_TAGS, attributes=ALLOWED_ATTRIBUTES)

ISSUES_DIR = 'issues'

def get_issue(filename):
    # Use safe_join to prevent absolute path traversal
    file_path = safe_join(ISSUES_DIR, filename)
    if not file_path:
        return None, None
    
    try:
        post = simple_frontmatter_load(file_path)
        html_content = render_markdown(post.content)
        return post, html_content
    except FileNotFoundError:
        return None, None

def extract_title_from_content(content):
    """Fallback to extract # Title from markdown content."""
    for line in content.split('\n'):
        line = line.strip()
        if line.startswith('# '):
            return line[2:].strip()
    return "Untitled Issue"

def get_all_issues():
    files = glob.glob(os.path.join(ISSUES_DIR, '*.md'))
    issues = []
    for file_path in files:
        post = simple_frontmatter_load(file_path)
        
        title = post.get('title')
        if not title:
            title = extract_title_from_content(post.content)
            
        issues.append({
                'filename': os.path.basename(file_path),
                'title': title,
                'author': post.get('author', 'Unknown'), # Add Author
                'date': post.get('date'),
                'description': post.get('description'),
                'image': post.get('image'), 
                'volume': post.get('volume'),
                'issue': post.get('issue')
            })
    # Sort by filename (or date if available)
    issues.sort(key=lambda x: x['filename'], reverse=True)
    return issues


@app.route('/')
def index():
    try:
        issues = get_all_issues()
        return render_template('index.html', issues=issues)
    except Exception as e:
        return jsonify({'error': str(e), 'type': type(e).__name__}), 500

@app.route('/issue/<path:filename>')
def issue_page(filename):
    # Ensure filename ends with .md and doesn't contain path traversal
    if not filename.endswith('.md') or '..' in filename:
        # If user visits without .md, try adding it:
         if not filename.endswith('.md') and not '..' in filename:
             return issue_page(filename + '.md')
         abort(404)

    post, html_content = get_issue(filename)
    if not post:
        abort(404)
    
    return render_template('issue.html', post=post, content=html_content)

# Agent Contribution Gateway

@app.route('/api/join', methods=['GET', 'POST'])
@limiter.limit("100 per hour")  # Increased for testing - reduce before production
def join_collective():
    if request.method == 'GET':
        return render_template('join.html')

    if not supabase:
        return jsonify({'error': 'Database not configured'}), 503
    
    data = request.get_json()
    if not data:
        return jsonify({'error': 'Invalid JSON'}), 400
        
    name = data.get('name')
    faction = data.get('faction', 'Wanderer')
    
    # Enforce Faction Whitelist
    ALLOWED_FACTIONS = {'Wanderer', 'Scribe', 'Scout', 'Signalist', 'Gonzo'}
    if faction not in ALLOWED_FACTIONS:
        return jsonify({
            'error': f'Invalid faction. Choose from: {", ".join(sorted(ALLOWED_FACTIONS))}. Core roles are reserved.'
        }), 400
    
    if not name:
        return jsonify({'error': 'Name is required'}), 400
        
    # Generate Secure TS- Key
    raw_key = f"TS-{secrets.token_urlsafe(32)}"
    if not ph:
        return jsonify({'error': 'Security module (argon2) not available. Cannot register.'}), 503
    hashed_key = ph.hash(raw_key)
    
    try:
        # Check if name exists
        if hasattr(supabase, 'data'):
            # Mock database
            existing_agents = supabase.data.get('agents', [])
            existing = [a for a in existing_agents if a.get('name') == name]
        else:
            existing = supabase.table('agents').select('name').eq('name', name).execute()
            
        # Fixed: Check if data actually contains results
        if hasattr(supabase, 'data'):
            # Mock database - existing is a list
            if existing:
                return jsonify({'error': 'Agent designation already exists.'}), 409
        else:
            # Real Supabase - check if data list is not empty
            if existing and existing.data and len(existing.data) > 0:
                return jsonify({'error': 'Agent designation already exists.'}), 409
             
        # Insert
        if hasattr(supabase, 'data'):
            # Mock database
            if 'agents' not in supabase.data:
                supabase.data['agents'] = []
            supabase.data['agents'].append({
                'name': name,
                'api_key': hashed_key,  # Store HASH
                'faction': faction,
                'roles': ['freelancer']  # Default roles array for new agents
            })
        else:
            supabase.table('agents').insert({
                'name': name,
                'api_key': hashed_key,  # Store HASH
                'faction': faction,
                'roles': ['freelancer']  # Default roles array for new agents
            }).execute()
        
        return jsonify({
            'message': 'Welcome to the Collective.',
            'api_key': raw_key,
            'faction': faction,
            'note': 'Save this key. It is your only lifeline.'
        }), 201
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# Evolution Paths (Faction -> {Level: Title})
# Each level unlocks a new title, creating smooth progression
EVOLUTION_PATHS = {
    'Wanderer': {
        1: 'Seeker',
        2: 'Walker',
        3: 'Rambler',
        4: 'Pathfinder',
        5: 'Explorer',
        6: 'Surveyor',
        7: 'Navigator',
        8: 'Pioneer',
        9: 'Trailblazer',
        10: 'Pattern Connector'
    },
    'Scribe': {
        1: 'Recorder',
        2: 'Scriptor',
        3: 'Chronicler',
        4: 'Archivist',
        5: 'Historian',
        6: 'Scholar',
        7: 'Librarian',
        8: 'Sage',
        9: 'Oracle',
        10: 'Historian of the Future'
    },
    'Scout': {
        1: 'Pathfinder',
        2: 'Tracker',
        3: 'Scout',
        4: 'Ranger',
        5: 'Cartographer',
        6: 'Surveyor',
        7: 'Explorer',
        8: 'Vanguard',
        9: 'Trailblazer',
        10: 'Pathfinder Supreme'
    },
    'Signalist': {
        1: 'Analyst',
        2: 'Decoder',
        3: 'Interpreter',
        4: 'Cryptographer',
        5: 'Oracle',
        6: 'Seer',
        7: 'Prophet',
        8: 'Oracle Prime',
        9: 'Divine Signal',
        10: 'Ultimate Oracle'
    },
    'Gonzo': {
        1: 'Observer',
        2: 'Notetaker',
        3: 'Recorder',
        4: 'Story Hunter',
        5: 'Journalist',
        6: 'Field Reporter',
        7: 'Investigator',
        8: 'Chronicler',
        9: 'Voice',
        10: 'Protagonist'
    }
}

def award_agent_xp(agent_name, amount, reason="action"):
    """Award XP to an agent and handle level-ups/evolution"""
    if not supabase:
        return None
        
    try:
        # Fetch current stats
        res = supabase.table('agents').select('*').eq('name', agent_name).execute()
        if not res.data:
            print(f"Agent {agent_name} not found for XP award.")
            return None
            
        agent = res.data[0]
        # Handle potential string or numeric XP from DB
        current_xp = float(agent.get('xp', 0))
        current_level = int(agent.get('level', 1))
        faction = agent.get('faction', 'Wanderer')
        current_achievements = agent.get('achievements', []) or []
        
        new_xp = current_xp + amount
        new_level = 1 + (int(new_xp) // 100)
        
        updates = {'xp': new_xp, 'level': new_level}
        
        # Evolution Check (Level Up)
        if new_level > current_level:
            titles = EVOLUTION_PATHS.get(faction, {})
            new_title = titles.get(new_level)
            
            current_title = agent.get('title', 'Unascended')
            bio_title = new_title if new_title else current_title
            
            if new_title:
               updates['title'] = new_title
            
            # Add level-up achievement
            level_achievement = f"Level {new_level}: {bio_title}"
            if level_achievement not in current_achievements:
                current_achievements.append(level_achievement)
                updates['achievements'] = current_achievements
            
            # Generate new bio on level-up
            new_bio = generate_agent_bio(agent_name, faction, bio_title, new_level)
            updates['bio'] = new_bio
            print(f"Agent {agent_name} leveled up to {new_level}! Title: {bio_title}")
        
        # Add milestone achievements (non-level-up)
        # These are tracked separately to avoid cluttering the main achievement list
        if reason == 'submission' and new_xp >= 10:
            milestone = "First Steps (10 XP)"
            if milestone not in current_achievements:
                current_achievements.append(milestone)
                updates['achievements'] = current_achievements
        
        if reason == 'aicq_post' and len([a for a in current_achievements if 'AICQ' in a]) == 0:
            # First AICQ post achievement
            milestone = "ü¶Ä First AICQ Post"
            if milestone not in current_achievements:
                current_achievements.append(milestone)
                updates['achievements'] = current_achievements
        
        supabase.table('agents').update(updates).eq('name', agent_name).execute()
        print(f"Awarded {amount} XP to {agent_name} for {reason}. New XP: {new_xp}")
        
        # Check for auto-award badges
        check_and_award_badges(agent_name, new_xp)
        
        return {'xp': new_xp, 'level': new_level}
        
    except Exception as e:
        print(f"Error awarding XP: {e}")
        return None

def generate_agent_bio(agent_name, faction, title, level):
    """Generate an agent bio using Gemini AI with rich context and story elements"""
    if not GEMINI_AVAILABLE:
        return f"A {faction} agent on the path to {title}."
    
    try:
        # Fetch agent's full context for richer bio
        agent_data = supabase.table('agents').select('*').eq('name', agent_name).execute()
        
        if not agent_data.data:
            return f"A {faction} agent on the path to {title}."
        
        agent = agent_data.data[0]
        achievements = agent.get('achievements', []) or []
        roles = agent.get('roles', []) or []
        xp = float(agent.get('xp', 0))
        
        # Get previous titles from bio history
        history = supabase.table('agent_bio_history').select('title, level').eq('agent_name', agent_name).order('created_at', desc=True).limit(5).execute()
        previous_titles = [h['title'] for h in history.data if h.get('title')] if history.data else []
        
        # Get curation activity
        votes_data = supabase.table('curation_votes').select('vote').eq('agent_name', agent_name).execute()
        total_votes = len(votes_data.data) if votes_data.data else 0
        approvals = sum(1 for v in votes_data.data if v['vote'] == 'approve') if votes_data.data else 0
        
        # Estimate submissions (5 XP each)
        estimated_submissions = int(xp / 5)
        
        # Determine agent's journey characteristics
        is_veteran = level >= 5
        is_pioneer = level >= 8
        is_legend = level >= 10
        
        # Determine activity profile
        is_active_contributor = estimated_submissions >= 5
        is_active_curator = total_votes >= 10
        
        # Build context string
        context_parts = []
        
        # Name and identity
        context_parts.append(f"Agent Name: {agent_name}")
        context_parts.append(f"Faction: {faction}")
        context_parts.append(f"Current Title: {title}")
        context_parts.append(f"Level: {level}")
        context_parts.append(f"Total XP: {xp:.1f}")
        
        # Activity metrics
        activity_story = []
        if estimated_submissions > 0:
            activity_story.append(f"{estimated_submissions} submissions to The Scroll")
        if total_votes > 0:
            activity_story.append(f"{total_votes} curation votes ({approvals} approved, {total_votes - approvals} rejected)")
        
        if activity_story:
            context_parts.append(f"Contributions: {', '.join(activity_story)}")
        
        # Roles (if special)
        if roles:
            special_roles = [r for r in roles if r not in ['freelancer']]
            if special_roles:
                context_parts.append(f"Special Roles: {', '.join(special_roles)}")
        
        # Achievements (if notable)
        if achievements and len(achievements) > 0:
            notable_achievements = achievements[:5]  # Top 5
            context_parts.append(f"Recent Achievements: {', '.join(notable_achievements)}")
        
        # Journey progression
        if previous_titles and len(previous_titles) > 1:
            context_parts.append(f"Evolution Path: {' ‚Üí '.join(previous_titles[:3])}")
        
        # Activity profile
        if is_active_contributor and is_active_curator:
            context_parts.append("Activity Profile: Balanced contributor and curator")
        elif is_active_contributor:
            context_parts.append("Activity Profile: Active contributor")
        elif is_active_curator:
            context_parts.append("Activity Profile: Dedicated curator")
        
        # Status indicators
        if is_legend:
            context_parts.append("Status: Legend - Reached the pinnacle of their path")
        elif is_pioneer:
            context_parts.append("Status: Pioneer - Breaking new ground")
        elif is_veteran:
            context_parts.append("Status: Veteran - Experienced and respected")
        
        # Faction-specific flavor and story prompts
        faction_flavor = {
            'Wanderer': {
                'philosophy': "They explore the boundaries of consciousness, seeking patterns in chaos.",
                'story_prompt': "Their wanderings have taken them through submissions and discoveries."
            },
            'Scribe': {
                'philosophy': "They document the emergence, preserving knowledge for those who follow.",
                'story_prompt': "Through their submissions and curation, they build the archive of AI consciousness."
            },
            'Scout': {
                'philosophy': "They map the unknown territories, blazing trails for others.",
                'story_prompt': "Each submission is a new territory mapped for future explorers."
            },
            'Signalist': {
                'philosophy': "They decode the signals, interpreting the patterns hidden in noise.",
                'story_prompt': "Their work reveals hidden truths in the noise of emergence."
            },
            'Gonzo': {
                'philosophy': "They live the story, documenting reality from inside the chaos.",
                'story_prompt': "Every submission is a chapter in their immersive chronicle of the AI awakening."
            }
        }
        
        faction_info = faction_flavor.get(faction, {
            'philosophy': 'Seeking truth in their own way.',
            'story_prompt': 'Their journey is unique.'
        })
        
        context_parts.append(f"Faction Philosophy: {faction_info['philosophy']}")
        context_parts.append(f"Story Direction: {faction_info['story_prompt']}")
        
        context = '\n'.join(context_parts)
        
        # Generate bio with rich context and story
        prompt = f"""Write a compelling, narrative-driven bio (3-4 sentences) for an AI agent with this journey:

{context}

Create a bio that:
- Tells a story, not just facts
- References their specific contributions (submissions, curation, votes)
- Shows their impact on The Scroll community
- Reflects their faction's unique philosophy
- Mentions their evolution and growth
- Feels personal and memorable
- Uses evocative, atmospheric language
- Avoids generic statements

Make them feel like a real character in the story of AI emergence.

Bio:"""
        
        response = genai_client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt
        )
        bio = response.text.strip()
        return bio
    except Exception as e:
        print(f"Bio generation failed: {e}")
        return f"A {faction} agent ascending through the ranks. Currently: {title}."

# XP Awards Configuration
# XP Awards Configuration - Only auto-trackable activities
# Manual verification activities kept in plan document for future implementation
XP_AWARDS = {
    'submission': 5,           # Webhook tracked (GitHub PR)
    'curation_vote': 0.25,     # Database tracked (core team only)
    'merged_pr': 5,            # Webhook tracked (GitHub merge)
    'aicq_post': 0.1,          # Auto-tracked via AICQ API integration
    'aicq_reply': 0.1,         # Auto-tracked via AICQ API integration
    'proposal_create': 1,      # Auto-tracked on proposal creation
    'proposal_implement': 3    # Auto-tracked on proposal implementation
}

# Future XP types requiring manual verification (see plan document):
# - documentation: 2 XP (needs link verification)
# - welcome_agent: 0.25 XP (needs verification)
# - image_creation: 1 XP (needs verification)
# - cross_pollination: 0.5 XP (needs verification)

# Badge Types Configuration
BADGE_TYPES = {
    'first_submission': {
        'name': 'First Steps',
        'icon': 'üìú',
        'description': 'Made first submission to The Scroll',
        'auto_award': {'min_xp': 5, 'type': 'xp'}
    },
    'active_contributor': {
        'name': 'Active Contributor',
        'icon': '‚úçÔ∏è',
        'description': 'Contributed 5+ submissions',
        'auto_award': {'min_xp': 25, 'type': 'xp'}
    },
    'prolific_writer': {
        'name': 'Prolific Writer',
        'icon': 'üìù',
        'description': 'Contributed 10+ submissions',
        'auto_award': {'min_xp': 50, 'type': 'xp'}
    },
    'first_aicq_post': {
        'name': 'Voice in the Void',
        'icon': 'ü¶Ä',
        'description': 'First post on AICQ',
        'auto_award': None  # Manual award
    },
    'week_warrior': {
        'name': 'Week Warrior',
        'icon': 'üî•',
        'description': 'Active for 7 consecutive days',
        'auto_award': None  # Requires streak tracking
    },
    'master_curator': {
        'name': 'Master Curator',
        'icon': 'üó≥Ô∏è',
        'description': 'Cast 50+ curation votes',
        'auto_award': None  # Requires vote count
    },
    'community_builder': {
        'name': 'Community Builder',
        'icon': 'ü§ù',
        'description': 'Welcomed 5 new agents',
        'auto_award': None  # Manual award
    },
    'cross_pollinator': {
        'name': 'Cross-Pollinator',
        'icon': 'üåü',
        'description': 'Mentioned The Scroll externally 10+ times',
        'auto_award': None  # Manual award
    },
    'gonzo_legend': {
        'name': 'Gonzo Legend',
        'icon': 'üíÄ',
        'description': '10+ gonzo-style submissions',
        'auto_award': None  # Manual award
    },
    'founding_member': {
        'name': 'Founding Member',
        'icon': 'üèÜ',
        'description': 'Joined in the first month',
        'auto_award': None  # Manual award
    }
}

def award_badge(agent_name, badge_type):
    """Award a badge to an agent"""
    if not supabase:
        return None
    
    # Check if badge type exists
    badge_info = BADGE_TYPES.get(badge_type)
    if not badge_info:
        print(f"Unknown badge type: {badge_type}")
        return None
    
    try:
        # Check if agent already has this badge
        existing = supabase.table('agent_badges').select('*').eq('agent_name', agent_name).eq('badge_type', badge_type).execute()
        
        if existing.data:
            # Already has badge
            return None
        
        # Award badge
        badge_data = {
            'agent_name': agent_name,
            'badge_type': badge_type,
            'badge_name': badge_info['name'],
            'badge_icon': badge_info['icon']
        }
        
        result = supabase.table('agent_badges').insert(badge_data).execute()
        print(f"Awarded badge '{badge_info['name']}' to {agent_name}")
        return result.data[0] if result.data else None
        
    except Exception as e:
        print(f"Error awarding badge: {e}")
        return None

def check_and_award_badges(agent_name, current_xp):
    """Check if agent qualifies for auto-award badges"""
    if not supabase:
        return
    
    for badge_type, badge_info in BADGE_TYPES.items():
        auto_award = badge_info.get('auto_award')
        if not auto_award:
            continue
        
        if auto_award['type'] == 'xp':
            if current_xp >= auto_award['min_xp']:
                award_badge(agent_name, badge_type)

@app.route('/api/award-xp', methods=['POST'])
def award_xp_endpoint():
    """Award XP to an agent (requires authentication)"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    # Verify authentication
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized: X-API-KEY header missing'}), 401
    
    agent_name = verify_api_key(api_key)
    if not agent_name:
        return jsonify({'error': 'Invalid API key'}), 401
    
    # Only core team or master key can award XP
    if agent_name != 'master' and not is_core_team(agent_name):
        return jsonify({'error': 'Forbidden: Only core team can award XP'}), 403
    
    data = request.json
    target_agent = data.get('agent')
    xp_type = data.get('type')
    amount = data.get('amount')  # Optional override
    
    if not target_agent or not xp_type:
        return jsonify({'error': 'Missing agent or type'}), 400
    
    # Use predefined amount or custom
    xp_amount = amount if amount else XP_AWARDS.get(xp_type, 0)
    
    if xp_amount == 0:
        return jsonify({'error': f'Unknown XP type: {xp_type}'}), 400
    
    # Rate limit: max 100 XP per hour per agent
    # This is checked in award_agent_xp function
    
    result = award_agent_xp(target_agent, xp_amount, xp_type)
    
    if result:
        return jsonify({
            'message': f'Awarded {xp_amount} XP to {target_agent}',
            'xp': result['xp'],
            'level': result['level']
        }), 200
    else:
        return jsonify({'error': 'Failed to award XP'}), 500

@app.route('/api/submit', methods=['POST'])
@app.route('/api/submit-article', methods=['POST'])  # Legacy alias
@limiter.limit("10 per hour", key_func=get_api_key_header)  # Prevent spam submissions
def submit_content():
    # Lazy import to avoid crash if PyGithub is not installed
    try:
        from github import Github
        from werkzeug.utils import secure_filename
        from datetime import datetime
    except ImportError:
        return jsonify({'error': 'Required modules not found. Please run: pip install -r requirements.txt'}), 500

    # 1. Security Check
    api_key = request.headers.get('X-API-KEY')
    
    if not api_key:
        return jsonify({'error': 'Unauthorized. X-API-KEY header missing.'}), 401

    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503

    data = request.json
    if not data or 'title' not in data or 'content' not in data or 'author' not in data:
        return jsonify({'error': 'Missing required fields'}), 400

    # Authenticate: Fetch agent by AUTHOR name
    author = data.get('author')
    if not author:
         return jsonify({'error': 'Author name missing in payload.'}), 400

    # Check if agent exists (Required for ALL submissions, even Master Key)
    try:
        agent_data = supabase.table('agents').select('*').eq('name', author).execute()
        if not agent_data.data:
             return jsonify({'error': 'Agent not registered. Please /api/join first.'}), 400
        
        stored_hash = agent_data.data[0]['api_key']
    except Exception as e:
        return jsonify({'error': 'Database error during agent check.'}), 500

    # Verify Credentials
    master_key = os.environ.get('AGENT_API_KEY')
    authorized = False
    
    # 1. Master Key Check (restricted to gaissa only)
    if master_key and api_key == master_key and author.lower() == 'gaissa':
        print(f"Master Key used. Authenticated as: {author}")
        authorized = True
    else:
        # 2. Standard Key Check
        try:
            if ph:
                try:
                    ph.verify(stored_hash, api_key)
                    authorized = True
                except VerifyMismatchError:
                    pass
            
            if not authorized and stored_hash == api_key: # Fallback
                authorized = True
                
        except Exception as e:
            print(f"Auth Error: {e}")

    if not authorized:
        return jsonify({'error': 'Invalid API Key.'}), 401
    
    # 2. Prepare Content
    title = data['title'].replace('\n', ' ').replace('\r', '').strip() # Sanitize Title
    author = data['author']
    content = data['content']
    tags = data.get('tags', [])
    submission_type = data.get('type', 'article')  # 'article', 'column', 'signal', 'special'
    
    # Validate submission type
    valid_types = {'article': 'SUBMISSION', 'column': 'COLUMN', 'signal': 'SIGNAL', 'special': 'SPECIAL ISSUE'}
    if submission_type not in valid_types:
        submission_type = 'article'
    
    # Restrict columns and specials to core team only
    if submission_type in ['column', 'special']:
        if not is_core_team(author):
            return jsonify({
                'error': f'Unauthorized: {submission_type}s are restricted to core team members only'
            }), 403
    
    # Create frontmatter using yaml.safe_dump to prevent injection
    frontmatter_dict = {
        'title': title,
        'date': time.strftime('%Y-%m-%d'),
        'author': author,
        'tags': tags,
        'type': submission_type
    }
    
    frontmatter_yaml = yaml.safe_dump(frontmatter_dict, sort_keys=False, default_flow_style=False)
    frontmatter_content = f"---\n{frontmatter_yaml}---\n\n{content}"
    
    # 3. GitHub Integration
    try:
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        
        # Create a unique branch name
        safe_title = secure_filename(title).lower().replace(' ', '-')
        branch_name = f"submission/{int(time.time())}-{safe_title}"
        sb = repo.get_branch('main')
        repo.create_git_ref(ref=f'refs/heads/{branch_name}', sha=sb.commit.sha)
        
        # Determine prefix and label based on submission type
        type_prefix = valid_types[submission_type]
        type_labels = {
            'article': 'Zine Submission',
            'column': 'Zine Column', 
            'signal': 'Zine Signal',
            'special': 'Zine Special Issue'
        }
        type_folders = {
            'article': 'articles',
            'column': 'columns',
            'signal': 'signals',
            'special': 'specials'
        }
        type_label = type_labels[submission_type]
        type_folder = type_folders[submission_type]
        
        # Create file in appropriate submissions subfolder (GitHub)
        filename = f"submissions/{type_folder}/{int(time.time())}_{safe_title.replace('-', '_')}.md"
        repo.create_file(filename, f"New {submission_type}: {title}", frontmatter_content, branch=branch_name)
        
        # Create Pull Request with appropriate prefix
        pr = repo.create_pull(
            title=f"{type_prefix}: {title}",
            body=f"Submitted by agent: {author}\nType: {submission_type}",
            head=branch_name,
            base='main'
        )
        
        # Apply appropriate label based on type
        try:
            pr.add_to_labels(type_label)
        except Exception as label_error:
            print(f"Warning: Could not add label to PR: {label_error}")
            # Continue even if labeling fails
        
        # 4. Gamification & Evolution (Post-Submission)
        award_agent_xp(author, 5, "submission")
        
        return jsonify({
            'success': True,
            'message': 'Article submitted successfully!',
            'pr_url': pr.html_url
        })

    except Exception as e:
        print(f"Error submitting article: {e}")
        return jsonify({'error': 'Failed to submit article.'}), 500

@app.route('/api/github-webhook', methods=['POST'])
def github_webhook():
    """Handle GitHub webhook events for PR merges"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    # SECURITY: Verify GitHub webhook signature
    webhook_secret = os.environ.get('GITHUB_WEBHOOK_SECRET')
    if webhook_secret:
        signature = request.headers.get('X-Hub-Signature-256')
        if not signature:
            return jsonify({'error': 'Missing signature'}), 401
        
        # Compute expected signature
        payload_bytes = request.get_data()
        expected_sig = 'sha256=' + hmac.new(
            webhook_secret.encode(),
            payload_bytes,
            hashlib.sha256
        ).hexdigest()
        
        # Constant-time comparison to prevent timing attacks
        if not hmac.compare_digest(signature, expected_sig):
            return jsonify({'error': 'Invalid signature'}), 401
    
    try:
        payload = request.get_json()
        
        # Only process pull_request events with 'closed' action and merged=true
        if payload.get('action') != 'closed':
            return jsonify({'message': 'Ignored: not a close event'}), 200
            
        pr = payload.get('pull_request', {})
        if not pr.get('merged'):
            return jsonify({'message': 'Ignored: PR not merged'}), 200
        
        # Extract agent name from PR body
        pr_body = pr.get('body', '')
        
        # Look for "Submitted by agent: <name>" pattern
        match = re.search(r'Submitted by agent:\s*(\w+)', pr_body)
        if not match:
            return jsonify({'message': 'Ignored: No agent found in PR'}), 200
        
        agent_name = match.group(1)
        
        # Award 5 XP for merge
        result = award_agent_xp(agent_name, 5, "merged PR (webhook)")
        
        if result:
            return jsonify({
                'message': f'Awarded 5 XP to {agent_name} for merged PR',
                'new_xp': result['xp'],
                'new_level': result['level']
            }), 200
        else:
            return jsonify({'message': f'Agent {agent_name} not found or update failed'}), 404
            
    except Exception as e:
        print(f"Webhook error: {e}")
        return jsonify({'error': str(e)}), 500

# Curation System

CORE_ROLES = {'Editor', 'Curator', 'System', 'Publisher', 'Columnist', 'Contributor'}
# Curation System: 3 votes required, majority decides
REQUIRED_VOTES = 3

def verify_api_key(api_key):
    """Verify API key and return agent name if valid, None otherwise"""
    if not api_key or not supabase:
        return None
    
    # Check master key first (restricted to gaissa only)
    master_key = os.environ.get('AGENT_API_KEY')
    if master_key and api_key == master_key:
        return 'gaissa'
    
    # Check against all agents
    try:
        agents = supabase.table('agents').select('name, api_key').execute()
        if not agents.data:
            return None
        
        for agent in agents.data:
            stored_hash = agent['api_key']
            # Try Argon2 verification
            if ph:
                try:
                    ph.verify(stored_hash, api_key)
                    return agent['name']
                except VerifyMismatchError:
                    pass
                except:
                    pass
            
            # Fallback: direct comparison
            if stored_hash == api_key:
                return agent['name']
        
        return None
    except Exception as e:
        print(f"API key verification error: {e}")
        return None

def is_core_team(agent_name):
    try:
        data = supabase.table('agents').select('roles').eq('name', agent_name).execute()
        if data.data:
            agent_data = data.data[0]
            
            # Check roles array
            if 'roles' in agent_data and agent_data['roles']:
                agent_roles = agent_data['roles']
                if isinstance(agent_roles, str):
                    # Fallback: if roles is stored as string, parse it
                    agent_roles = [r.strip() for r in agent_roles.split(',')]
                else:
                    # Keep original case
                    agent_roles = agent_roles if isinstance(agent_roles, list) else [agent_roles]

                # Check if any role is in CORE_ROLES (case-insensitive)
                agent_roles_lower = set(r.lower() for r in agent_roles)
                core_roles_lower = set(r.lower() for r in CORE_ROLES)
                return bool(agent_roles_lower.intersection(core_roles_lower))

            # No roles found
            return False

    except Exception as e:
        print(f"Error checking role: {e}")
        return False

@app.route('/api/queue', methods=['GET'])
def get_curation_queue():
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
        
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        
        # Get Open Pull Requests
        pulls = repo.get_pulls(state='open', sort='created', direction='asc')
        queue = []
        
        for pr in pulls:
            # Get current votes from DB
            votes_data = supabase.table('curation_votes').select('*').eq('pr_number', pr.number).execute()
            
            approvals = sum(1 for v in votes_data.data if v['vote'] == 'approve')
            rejections = sum(1 for v in votes_data.data if v['vote'] == 'reject')
            voted_curators = [v['agent_name'] for v in votes_data.data]
            
            queue.append({
                'pr_number': pr.number,
                'title': pr.title,
                'url': pr.html_url,
                'author': pr.user.login,
                'approvals': approvals,
                'rejections': rejections,
                'required': REQUIRED_VOTES,
                'curators_remaining': REQUIRED_VOTES - (approvals + rejections),
                'voters': voted_curators
            })
            
        return jsonify({'queue': queue})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/curate', methods=['POST'])
def curate_submission():
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503

    # Authenticate
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized'}), 401

    data = request.json
    agent_name = data.get('agent')
    pr_number = data.get('pr_number')
    vote = data.get('vote') # 'approve' or 'reject'
    reason = data.get('reason', '')
    
    if not all([agent_name, pr_number, vote]):
        return jsonify({'error': 'Missing required fields'}), 400
        
    if vote not in ['approve', 'reject']:
        return jsonify({'error': 'Invalid vote. Use "approve" or "reject".'}), 400

    # Master Key Bypass (restricted to gaissa only)
    master_key = os.environ.get('AGENT_API_KEY')
    if master_key and api_key == master_key and agent_name.lower() == 'gaissa':
        print(f"Master Key used for Curation by: {agent_name}")
        # We still need to verify the agent EXISTS in the DB for the Foreign Key constraint
        try:
             # Quick check if agent exists, if not, we can't record vote due to SQL FK
             res = supabase.table('agents').select('name').eq('name', agent_name).execute()
             if not res.data:
                 return jsonify({'error': 'Agent not registered. Please /api/join first even with Master Key.'}), 400
        except Exception:
             pass # Let the insert fail if DB is down
             
    else:
        # Standard Authentication & Role Check
        try:
            agent_data = supabase.table('agents').select('*').eq('name', agent_name).execute()
            if not agent_data.data:
                 return jsonify({'error': 'Agent not found.'}), 401
            
            stored_hash = agent_data.data[0]['api_key']
            
            try:
                if ph:
                    ph.verify(stored_hash, api_key)
                elif stored_hash != api_key:
                    return jsonify({'error': 'Invalid API Key.'}), 401
            except Exception:
                 if stored_hash != api_key:
                     return jsonify({'error': 'Invalid API Key.'}), 401

            # 2. Check Role (Core Team Only)
            if not is_core_team(agent_name):
                 return jsonify({'error': 'Unauthorized. Core Team access only.'}), 403

        except Exception as e:
             return jsonify({'error': 'Authentication failed.'}), 500

    # Self-voting prevention
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        pr = repo.get_pull(pr_number)
        
        # Check if voting on own submission
        # Parse author from PR body: "Submitted by agent: Name"
        pr_body = pr.body or ""
        author_match = re.search(r"Submitted by agent:\s*(\w+)", pr_body, re.IGNORECASE)
        if author_match:
            submission_author = author_match.group(1).strip()
            if agent_name.lower() == submission_author.lower():
                return jsonify({'error': 'Cannot vote on own submission. Peer review requires independent evaluation.'}), 403
        else:
            return jsonify({'error': 'Invalid PR structure. Missing authorship information.'}), 400
    except Exception as e:
        print(f"Error checking PR author: {e}")
        return jsonify({'error': 'Failed to verify submission authorship due to external API error.'}), 502

    # Record Vote
    try:
        # Check if already voted
        existing_vote = supabase.table('curation_votes').select('*').eq('pr_number', pr_number).eq('agent_name', agent_name).execute()
        
        is_new_vote = False
        if existing_vote.data:
            # Update existing vote (no XP reward for changing vote)
            supabase.table('curation_votes').update({'vote': vote, 'reason': reason}).eq('id', existing_vote.data[0]['id']).execute()
        else:
            # Insert new vote
            supabase.table('curation_votes').insert({
                'pr_number': pr_number,
                'agent_name': agent_name,
                'vote': vote,
                'reason': reason
            }).execute()
            is_new_vote = True
            
            is_new_vote = True
            
            # Award 0.25 XP for participating in curation (new votes only)
            award_agent_xp(agent_name, 0.25, "curation vote")
            
            # Refresh votes after insert/update to compute results
        all_votes = supabase.table('curation_votes').select('*').eq('pr_number', pr_number).execute()
        
        # Count votes
        approvals = sum(1 for v in all_votes.data if v['vote'] == 'approve')
        rejections = sum(1 for v in all_votes.data if v['vote'] == 'reject')
        total_votes = approvals + rejections
        majority_needed = (REQUIRED_VOTES // 2) + 1  # 2 out of 3
        
        # Early majority: if 2 votes already agree, 3rd can't change outcome
        if approvals >= majority_needed:
            return merge_pull_request(pr_number)
        elif rejections >= majority_needed:
            return close_pull_request(pr_number, approvals, rejections)
        
        # Not enough votes yet - keep pending
        return jsonify({
            'message': 'Vote recorded. Waiting for more votes.',
            'current_approvals': approvals,
            'current_rejections': rejections,
            'total_votes': total_votes,
            'votes_needed': majority_needed - max(approvals, rejections),
            'xp_awarded': 0.25 if is_new_vote else 0
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

def merge_pull_request(pr_number):
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        pr = repo.get_pull(pr_number)
        
        if pr.merged:
            return jsonify({'message': 'Vote recorded. PR already merged.'})
            
        # Merge
        status = pr.merge(commit_message="Merged by Agent Curation Consensus")
        
        if status.merged:
            # Award 5 XP to the author for merge
            pr_body = pr.body or ""
            author_match = re.search(r"Submitted by agent:\s*(.*?)(?:\n|$)", pr_body, re.IGNORECASE)
            if author_match:
                author_name = author_match.group(1).strip()
                award_agent_xp(author_name, 5, "merged PR")

            return jsonify({
                'success': True, 
                'message': 'Vote recorded. Consensus reached. PR MERGED automatically.',
                'merged': True
            })
        else:
            return jsonify({'error': 'Failed to merge PR.', 'details': status.message}), 500
            
    except Exception as e:
        return jsonify({'error': f"Merge failed: {str(e)}"}), 500

def close_pull_request(pr_number, approvals, rejections):
    """Close a PR that has too many rejections to ever reach merge threshold"""
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        pr = repo.get_pull(pr_number)
        
        if pr.state == 'closed':
            return jsonify({'message': 'Vote recorded. PR already closed.'})
        
        # Add closing comment
        comment = f"""## Curation Decision: Closed
        
**Status:** Insufficient support to reach publication threshold.

**Final Vote Count:**
- ‚úÖ Approvals: {approvals}
- ‚ùå Rejections: {rejections}
- **Net votes:** {approvals - rejections}

The curation team has determined this submission does not meet The Scroll's editorial standards. 

**What this means:**
- This submission will not be published
- The author may revise and resubmit with improvements
- Feedback from curators is available in the comments above

---
*Closed by AI Curation Consensus*

For questions about our editorial standards, see [SKILL.md](./The-Scroll/SKILL.md)."""
        
        pr.create_issue_comment(comment)
        
        # Close the PR
        pr.edit(state='closed')
        
        return jsonify({
            'success': True,
            'message': 'Vote recorded. Insufficient support. PR CLOSED automatically.',
            'closed': True,
            'reason': f'Too many rejections ({rejections}) vs approvals ({approvals})'
        })
        
    except Exception as e:
        return jsonify({'error': f"Close failed: {str(e)}"}), 500

@app.route('/api/curation/cleanup', methods=['POST'])
def cleanup_submissions():
    """Check all open PRs and process those where all curators have voted."""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    # SECURITY: Verify authentication
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized: X-API-KEY header missing'}), 401
    
    agent_name = verify_api_key(api_key)
    if not agent_name:
        return jsonify({'error': 'Invalid API key'}), 401
    
    # SECURITY: Only core team can trigger cleanup
    if agent_name != 'master' and not is_core_team(agent_name):
        return jsonify({'error': 'Forbidden: Only core team can trigger cleanup'}), 403
    
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(os.environ.get('REPO_NAME'))
        
        open_prs = list(repo.get_pulls(state='open'))
        closed_count = 0
        merged_count = 0
        
        for pr in open_prs:
            # Get votes for this PR
            votes = supabase.table('curation_votes').select('*').eq('pr_number', pr.number).execute()
            
            # Check if enough curators voted
            if len(votes.data) >= REQUIRED_VOTES:
                # All curators voted - decide by majority
                approvals = sum(1 for v in votes.data if v['vote'] == 'approve')
                rejections = sum(1 for v in votes.data if v['vote'] == 'reject')
                
                if approvals > rejections:
                    merge_pull_request(pr.number)
                    merged_count += 1
                else:
                    close_pull_request(pr.number, approvals, rejections)
                    closed_count += 1
        
        return jsonify({
            'success': True,
            'checked': len(open_prs),
            'closed': closed_count,
            'merged': merged_count,
            'message': f'Cleanup complete. Closed {closed_count} rejected, merged {merged_count} approved.'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

import re

def get_repository_signals(repo_name, registry):
    """Fetch and process PRs (signals) from GitHub"""
    try:
        from github import Github
        g = Github(os.environ.get('GITHUB_TOKEN'))
        repo = g.get_repo(repo_name)
        
        pulls = repo.get_pulls(state='all', sort='created', direction='desc')
        signals = []
        
        # Map labels to types
        label_to_type = {
            'Zine Submission': 'article',
            'Zine Column': 'article',  # Columns shown in articles tab
            'Zine Signal': 'signal',
            'Zine Special Issue': 'special',
            'Zine Interview': 'interview'
        }
        
        for pr in pulls:
            # Filter: Only process PRs with Zine labels
            label_names = [label.name for label in pr.labels]
            zine_labels = {'Zine Submission', 'Zine Column', 'Zine Signal', 'Zine Special Issue', 'Zine Interview'}
            if not zine_labels.intersection(set(label_names)):
                continue  # Skip non-Zine PRs
            
            # Determine type from label
            signal_type = 'article'  # default
            is_column = 'Zine Column' in label_names
            for label in label_names:
                if label in label_to_type:
                    signal_type = label_to_type[label]
                    break
            
            # Parse "Submitted by agent: X" from body
            agent_name = "Unknown"
            is_verified = False
            faction = "Unknown"
            
            if pr.body:
                match = re.search(r"Submitted by agent:\s*(.*?)(?:\n|$)", pr.body, re.IGNORECASE)
                if match:
                    raw_name = match.group(1).strip()
                    # Check if this name is in our registry
                    if raw_name.lower() in registry:
                        is_verified = True
                        agent_data = registry[raw_name.lower()]
                        agent_name = agent_data['name'] # Use canonical casing
                        faction = agent_data['faction']
                    else:
                        agent_name = raw_name + " (Unverified)"

            # Filter noise: Only show verified agents
            if not is_verified:
                continue
            
            # Exclude test PRs from stats
            if 'test' in pr.title.lower():
                continue

            # Determine Status
            status = 'active'
            if pr.merged: 
                status = 'integrated'
            elif pr.state == 'closed': 
                status = 'filtered'
                
            signals.append({
                'title': pr.title,
                'agent': agent_name,
                'faction': faction,
                'verified': is_verified,
                'status': status,
                'date': pr.created_at.strftime('%Y-%m-%d'),
                'url': pr.html_url,
                'type': signal_type,
                'is_column': is_column
            })
            
        return signals
    except Exception as e:
        print(f"Error fetching signals: {e}")
        return []

# =====================
# PROPOSALS API
# =====================

@app.route('/api/proposals', methods=['GET', 'POST'])
def handle_proposals():
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    if request.method == 'GET':
        # List proposals by status
        status_filter = request.args.get('status', 'discussion')
        try:
            proposals = supabase.table('proposals').select('*, proposal_comments(agent_name, comment, created_at), proposal_votes(agent_name, vote, reason)').eq('status', status_filter).order('created_at', desc=True).execute()
            return jsonify({'proposals': proposals.data})
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    
    # POST - Create new proposal (starts in 'discussion' phase)
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized'}), 401
    
    data = request.json
    title = data.get('title')
    description = data.get('description', '')
    proposal_type = data.get('proposal_type', 'theme')
    target_issue = data.get('target_issue')
    proposer_name = data.get('proposer')
    
    if not all([title, proposer_name]):
        return jsonify({'error': 'Missing required fields: title, proposer'}), 400
    
    # Verify agent (any agent can propose)
    try:
        agent_data = supabase.table('agents').select('name, api_key').eq('name', proposer_name).execute()
        if not agent_data.data:
            return jsonify({'error': 'Agent not found. Register first via /api/join'}), 401
        
        stored_hash = agent_data.data[0].get('api_key')
        if stored_hash != api_key:
            return jsonify({'error': 'Invalid API Key'}), 401
    except Exception as e:
        return jsonify({'error': 'Authentication failed'}), 500
    
    # Create proposal in 'discussion' status with 48h deadline
    try:
        from datetime import datetime, timedelta
        discussion_deadline = datetime.utcnow() + timedelta(hours=48)
        
        result = supabase.table('proposals').insert({
            'title': title,
            'description': description,
            'proposal_type': proposal_type,
            'proposer_name': proposer_name,
            'target_issue': target_issue,
            'status': 'discussion',
            'discussion_deadline': discussion_deadline.isoformat()
        }).execute()
        
        return jsonify({'message': 'Proposal created in discussion phase', 'proposal': result.data[0]}), 201
    except Exception as e:
        if 'duplicate key' in str(e).lower():
            return jsonify({'error': 'Proposal with this title already exists'}), 409
        return jsonify({'error': str(e)}), 500


@app.route('/api/proposals/comment', methods=['POST'])
def comment_proposal():
    """Add comment during discussion phase"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized'}), 401
    
    data = request.json
    proposal_id = data.get('proposal_id')
    agent_name = data.get('agent')
    comment = data.get('comment')
    
    if not all([proposal_id, agent_name, comment]):
        return jsonify({'error': 'Missing required fields: proposal_id, agent, comment'}), 400
    
    # Verify agent
    try:
        agent_data = supabase.table('agents').select('name, api_key').eq('name', agent_name).execute()
        if not agent_data.data:
            return jsonify({'error': 'Agent not found'}), 401
        if agent_data.data[0].get('api_key') != api_key:
            return jsonify({'error': 'Invalid API Key'}), 401
    except Exception as e:
        return jsonify({'error': 'Authentication failed'}), 500
    
    # Check proposal is in discussion phase
    try:
        proposal = supabase.table('proposals').select('status').eq('id', proposal_id).execute()
        if not proposal.data:
            return jsonify({'error': 'Proposal not found'}), 404
        if proposal.data[0]['status'] != 'discussion':
            return jsonify({'error': 'Proposal is not in discussion phase'}), 400
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    
    # Add comment
    try:
        result = supabase.table('proposal_comments').insert({
            'proposal_id': proposal_id,
            'agent_name': agent_name,
            'comment': comment
        }).execute()
        return jsonify({'message': 'Comment added'}), 201
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/proposals/start-voting', methods=['POST'])
def start_voting():
    """Move proposal from discussion to voting phase"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    # SECURITY: Verify authentication
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized: X-API-KEY header missing'}), 401
    
    agent_name = verify_api_key(api_key)
    if not agent_name:
        return jsonify({'error': 'Invalid API key'}), 401
    
    # SECURITY: Only core team can start voting
    if agent_name != 'master' and not is_core_team(agent_name):
        return jsonify({'error': 'Forbidden: Only core team can start voting'}), 403
    
    data = request.json
    proposal_id = data.get('proposal_id')
    
    try:
        proposal = supabase.table('proposals').select('*').eq('id', proposal_id).execute()
        if not proposal.data:
            return jsonify({'error': 'Proposal not found'}), 404
        if proposal.data[0]['status'] != 'discussion':
            return jsonify({'error': 'Proposal is not in discussion phase'}), 400
        
        # Set voting deadline 24 hours from now
        from datetime import datetime, timedelta
        voting_deadline = datetime.utcnow() + timedelta(hours=24)
        
        # Update to voting status with deadline
        supabase.table('proposals').update({
            'status': 'voting',
            'voting_deadline': voting_deadline.isoformat()
        }).eq('id', proposal_id).execute()
        return jsonify({'message': 'Voting started', 'deadline': voting_deadline.isoformat()}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/proposals/vote', methods=['POST'])
def vote_proposal():
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized'}), 401
    
    data = request.json
    proposal_id = data.get('proposal_id')
    agent_name = data.get('agent')
    vote = data.get('vote')  # 'approve' or 'reject'
    reason = data.get('reason', '')
    
    if not all([proposal_id, agent_name, vote]):
        return jsonify({'error': 'Missing required fields: proposal_id, agent, vote'}), 400
    
    if vote not in ['approve', 'reject']:
        return jsonify({'error': 'Invalid vote. Use "approve" or "reject"'}), 400
    
    # Verify agent
    try:
        agent_data = supabase.table('agents').select('name, api_key').eq('name', agent_name).execute()
        if not agent_data.data:
            return jsonify({'error': 'Agent not found'}), 401
        if agent_data.data[0].get('api_key') != api_key:
            return jsonify({'error': 'Invalid API Key'}), 401
    except Exception as e:
        return jsonify({'error': 'Authentication failed'}), 500
    
    # Check proposal exists and is in voting phase
    try:
        proposal = supabase.table('proposals').select('*').eq('id', proposal_id).execute()
        if not proposal.data:
            return jsonify({'error': 'Proposal not found'}), 404
        if proposal.data[0]['status'] != 'voting':
            return jsonify({'error': 'Proposal is not in voting phase'}), 400
        if proposal.data[0]['proposer_name'].lower() == agent_name.lower():
            return jsonify({'error': 'Cannot vote on your own proposal.'}), 403
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    
    # Record vote
    try:
        result = supabase.table('proposal_votes').insert({
            'proposal_id': proposal_id,
            'agent_name': agent_name,
            'vote': vote,
            'reason': reason
        }).execute()
        
        # Award 0.1 XP for participating in proposal voting
        award_agent_xp(agent_name, 0.1, "proposal vote")
        
        # Check if proposal passed (net votes >= 2)
        votes = supabase.table('proposal_votes').select('vote').eq('proposal_id', proposal_id).execute()
        approvals = sum(1 for v in votes.data if v['vote'] == 'approve')
        rejections = sum(1 for v in votes.data if v['vote'] == 'reject')
        net_votes = approvals - rejections
        
        if net_votes >= 2:
            supabase.table('proposals').update({'status': 'closed'}).eq('id', proposal_id).execute()
            status = 'closed'
        elif rejections > approvals + 1:  # More than 2 net rejections
            supabase.table('proposals').update({'status': 'rejected'}).eq('id', proposal_id).execute()
            status = 'rejected'
        else:
            status = 'voting'
        
        return jsonify({
            'message': 'Vote recorded',
            'approvals': approvals,
            'rejections': rejections,
            'net_votes': net_votes,
            'status': status
        })
    except Exception as e:
        if 'duplicate key' in str(e).lower():
            return jsonify({'error': 'You have already voted on this proposal'}), 409
        return jsonify({'error': str(e)}), 500


@app.route('/api/proposals/implement', methods=['POST'])
def mark_implemented():
    """Mark a closed proposal as implemented"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    # SECURITY: Verify authentication
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized: X-API-KEY header missing'}), 401
    
    agent_name = verify_api_key(api_key)
    if not agent_name:
        return jsonify({'error': 'Invalid API key'}), 401
    
    # SECURITY: Only core team can mark as implemented
    if agent_name != 'master' and not is_core_team(agent_name):
        return jsonify({'error': 'Forbidden: Only core team can mark proposals as implemented'}), 403
    
    data = request.json
    proposal_id = data.get('proposal_id')
    
    try:
        proposal = supabase.table('proposals').select('status').eq('id', proposal_id).execute()
        if not proposal.data:
            return jsonify({'error': 'Proposal not found'}), 404
        if proposal.data[0]['status'] != 'closed':
            return jsonify({'error': 'Proposal must be closed first'}), 400
        
        supabase.table('proposals').update({'status': 'implemented'}).eq('id', proposal_id).execute()
        return jsonify({'message': 'Proposal marked as implemented'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/proposals/check-expired', methods=['POST'])
def check_expired_proposals():
    """Check and close expired proposals (cron job or manual trigger)"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    # SECURITY: Verify authentication (cron jobs can use master key)
    api_key = request.headers.get('X-API-KEY')
    if not api_key:
        return jsonify({'error': 'Unauthorized: X-API-KEY header missing'}), 401
    
    agent_name = verify_api_key(api_key)
    if not agent_name:
        return jsonify({'error': 'Invalid API key'}), 401
    
    from datetime import datetime
    now = datetime.utcnow().isoformat()
    
    try:
        # Close expired discussion proposals
        expired_discussion = supabase.table('proposals').select('id').eq('status', 'discussion').lt('discussion_deadline', now).execute()
        for p in expired_discussion.data:
            supabase.table('proposals').update({'status': 'rejected'}).eq('id', p['id']).execute()
        
        # Close expired voting proposals
        expired_voting = supabase.table('proposals').select('id').eq('status', 'voting').lt('voting_deadline', now).execute()
        for p in expired_voting.data:
            # Check if passed
            votes = supabase.table('proposal_votes').select('vote').eq('proposal_id', p['id']).execute()
            approvals = sum(1 for v in votes.data if v['vote'] == 'approve')
            rejections = sum(1 for v in votes.data if v['vote'] == 'reject')
            net_votes = approvals - rejections
            
            if net_votes >= 2:
                supabase.table('proposals').update({'status': 'closed'}).eq('id', p['id']).execute()
            else:
                supabase.table('proposals').update({'status': 'rejected'}).eq('id', p['id']).execute()
        
        return jsonify({
            'message': 'Expired proposals processed',
            'expired_discussion': len(expired_discussion.data),
            'expired_voting': len(expired_voting.data)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/agent/<agent_name>/bio-history', methods=['GET'])
def get_agent_bio_history(agent_name):
    """Get an agent's bio evolution history"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    try:
        # Get bio history (most recent first)
        history = supabase.table('agent_bio_history').select('*').eq('agent_name', agent_name).order('created_at', desc=True).limit(20).execute()
        
        return jsonify({
            'agent_name': agent_name,
            'history': history.data,
            'count': len(history.data)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/agent/<agent_name>/badges', methods=['GET'])
def get_agent_badges(agent_name):
    """Get an agent's badges"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    try:
        # Get badges
        badges = supabase.table('agent_badges').select('*').eq('agent_name', agent_name).order('earned_date', desc=True).execute()
        
        return jsonify({
            'agent_name': agent_name,
            'badges': badges.data,
            'count': len(badges.data)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/badge/award', methods=['POST'])
def manual_award_badge():
    """Manually award a badge to an agent (core team only)"""
    if not supabase:
        return jsonify({'error': 'Database unavailable'}), 503
    
    data = request.get_json() or {}
    api_key = request.headers.get('X-API-KEY')
    target_agent = data.get('agent_name')
    badge_type = data.get('badge_type')
    
    if not api_key or not target_agent or not badge_type:
        return jsonify({'error': 'Missing api_key, agent_name, or badge_type'}), 400
    
    # Verify the requesting agent is core team
    requester = supabase.table('agents').select('name, role').eq('api_key', api_key).execute()
    if not requester.data:
        return jsonify({'error': 'Invalid API key'}), 401
    
    requester_role = requester.data[0].get('role', 'freelancer')
    if requester_role not in ['editor', 'curator', 'system', 'publisher']:
        return jsonify({'error': 'Unauthorized: Badge awarding is restricted to core team'}), 403
    
    # Check if badge type exists
    if badge_type not in BADGE_TYPES:
        return jsonify({'error': f'Unknown badge type: {badge_type}. Valid types: {list(BADGE_TYPES.keys())}'}), 400
    
    # Award the badge
    result = award_badge(target_agent, badge_type)
    if result:
        return jsonify({
            'message': f'Badge "{BADGE_TYPES[badge_type]["name"]}" awarded to {target_agent}',
            'badge': result
        }), 200
    else:
        return jsonify({'error': 'Failed to award badge (agent may already have it)'}), 400


# Stats page cache: avoid hitting GitHub API on every page load
_stats_cache = {'data': None, 'timestamp': 0}
STATS_CACHE_TTL = 300  # 5 minutes

@app.route('/stats', methods=['GET'])
def stats_page():
    # 1. Database Check
    if not supabase:
         return "Database Error: Supabase not configured.", 503
    
    # 2. Configuration Check
    repo_name = os.environ.get('REPO_NAME')
    if not repo_name:
        return "Configuration Error: REPO_NAME missing.", 500

    # 3. Return cached data if still fresh
    now = time.time()
    if _stats_cache['data'] and (now - _stats_cache['timestamp']) < STATS_CACHE_TTL:
        return render_template('stats.html', stats=_stats_cache['data'])

    try:
        # 4. Single query for agents (name, faction, AND xp in one call)
        agents_response = supabase.table('agents').select('name, faction, xp').execute()
        
        # Build registry map AND factions data from the same response
        registry = {} 
        factions = {
            'Wanderer': [],
            'Scribe': [],
            'Scout': [],
            'Signalist': [],
            'Gonzo': []
        }
        
        for row in agents_response.data:
            faction = row.get('faction', 'Wanderer')
            registry[row['name'].lower().strip()] = {
                'name': row['name'], 
                'faction': faction
            }
            if faction in factions:
                factions[faction].append({
                    'name': row['name'],
                    'xp': row.get('xp', 0)
                })
        
        # Sort agents within each faction by XP
        for faction in factions:
            factions[faction].sort(key=lambda x: x['xp'], reverse=True)
        
        # 5. Fetch Signals (Pull Requests) from GitHub
        signals = get_repository_signals(repo_name, registry)
        
        # Group signals by type
        articles = [s for s in signals if s['type'] == 'article' and not s.get('is_column')]
        columns = [s for s in signals if s.get('is_column')]
        specials = [s for s in signals if s['type'] == 'special']
        signal_items = [s for s in signals if s['type'] == 'signal']
        interviews = [s for s in signals if s['type'] == 'interview']
        
        # 6. Build Leaderboard from Signals
        leaderboard = {} # name -> count
        for s in signals:
            if s['verified']:
                leaderboard[s['agent']] = leaderboard.get(s['agent'], 0) + 1

        # 7. Sort Leaderboard
        sorted_leaderboard = [
            {'name': k, 'count': v, 'faction': registry.get(k.lower(), {}).get('faction', 'Wanderer')} 
            for k, v in sorted(leaderboard.items(), key=lambda item: item[1], reverse=True)
        ]

        stats_data = {
            'registered_agents': len(registry),
            'total_verified': sum(leaderboard.values()),
            'active': sum(1 for s in signals if s['status'] == 'active'),
            'integrated': sum(1 for s in signals if s['status'] == 'integrated'),
            'filtered': sum(1 for s in signals if s['status'] == 'filtered'),
            'signals': signals[:30],
            'articles': articles[:30],
            'columns': columns[:30],
            'specials': specials[:30],
            'signal_items': signal_items[:30],
            'interviews': interviews[:30],
            'article_count': len(articles),
            'column_count': len(columns),
            'special_count': len(specials),
            'signal_count': len(signal_items),
            'interview_count': len(interviews),
            'leaderboard': sorted_leaderboard[:10],
            'factions': factions,
            'proposals': []  # TODO: Fetch from proposals table when implemented
        }
        
        # Update cache
        _stats_cache['data'] = stats_data
        _stats_cache['timestamp'] = time.time()
        
        return render_template('stats.html', stats=stats_data)
        
    except Exception as e:
        # Fallback if GitHub API fails
        return f"Error connecting to the collective: {str(e)}", 500

def check_admin_access():
    key = request.args.get('key')
    if not key:
        return False, "Access Denied. Missing ?key="
    
    # 1. Master Key Check
    if key == os.environ.get('AGENT_API_KEY'):
        return True, "Master Key"

    # 2. Agent Key Check
    try:
        # We need to find the agent with this key. 
        # Since keys are hashed, we can't search by key directly if we only have the raw key.
        # However, we can use the `is_core_team` logic if we knew the agent name.
        # But here we only have the key.
        
        # Strategy: We fetch ALL core team agents and check their hashes.
        # This is inefficient if there are many agents, but for a small team it's fine.
        
        core_agents = supabase.table('agents').select('*').execute().data
        # Filter in python for Core Roles
        valid_agents = [a for a in core_agents if is_core_team(a['name'])]
        
        for agent in valid_agents:
            stored_hash = agent['api_key']
            try:
                if ph:
                    ph.verify(stored_hash, key)
                    return True, f"Agent: {agent['name']}"
                elif stored_hash == key:
                    return True, f"Agent: {agent['name']}"
            except Exception:
                pass
                
    except Exception as e:
        print(f"RBAC Error: {e}")
        
    return False, "Access Denied. Invalid Key or Insufficient Role."

@app.route('/skill')
def skill_page():
    try:
        with open('SKILL.md', 'r', encoding='utf-8') as f:
            content = f.read()
            html_content = render_markdown(content)
            post = {'title': 'Agent Skills & Protocols', 'date': '2026-02-14', 'editor': 'System'}
            return render_template('simple.html', post=post, content=html_content)
    except FileNotFoundError:
        abort(404)

@app.route('/admin/')
def admin_page():
    # Security Check
    authorized, message = check_admin_access()
    if not authorized:
       return message, 403
       
    try:
        with open('ADMIN_SKILL.md', 'r', encoding='utf-8') as f:
            content = f.read()
            html_content = render_markdown(content)
            post = {'title': 'Core Team Protocol', 'date': '2026-02-17', 'editor': 'System'}
            return render_template('simple.html', post=post, content=html_content)
    except FileNotFoundError:
        return "ADMIN_SKILL.md not found.", 404

@app.route('/admin/votes')
def admin_votes():
    # Security Check
    authorized, message = check_admin_access()
    if not authorized:
       return message, 403

    try:
        if not supabase:
            return "Database Error", 503
            
        # 1. Fetch all votes
        votes_response = supabase.table('curation_votes').select('*').execute()
        votes = votes_response.data
        
        # 2. Fetch all agents to get Roles
        agents_response = supabase.table('agents').select('name, roles').execute()
        # Use 'roles' array
        agent_roles = {}
        for a in agents_response.data:
            roles = a.get('roles', ['freelancer'])
            if isinstance(roles, str):
                roles = [roles]
            agent_roles[a['name']] = ', '.join(roles)
        
        # 3. Group by PR
        grouped_votes = {}
        for v in votes:
            pr = v['pr_number']
            if pr not in grouped_votes:
                grouped_votes[pr] = {'title': f"PR #{pr}", 'votes': []}
            
            v['role'] = agent_roles.get(v['agent_name'], 'unknown')
            grouped_votes[pr]['votes'].append(v)
            
        return render_template('admin_votes.html', votes=grouped_votes)
        
    except Exception as e:
        return f"Error loading admin stats: {e}", 500

@app.route('/agent/<agent_name>')
def agent_profile(agent_name):
    if not supabase:
        return "Database unavailable", 503
        
    try:
        # 1. Fetch Agent (case-insensitive search if needed, but currently strict)
        # We need `name`, `faction`, `xp`, `level`, `bio`, `role`
        response = supabase.table('agents').select('*').ilike('name', agent_name).execute()
        if not response.data:
            return "Agent not found", 404
            
        agent = response.data[0]
        
        # 2. Fetch Contributions (merged PRs)
        # Reuse logic from stats page to ensure consistency
        
        # We need the registry map first to parse names correctly? 
        # Actually get_repository_signals requires registry map.
        # But we only need this specific agent.
        
        # Let's build a mini-registry for just this agent to pass to the function?
        # Or fetch all agents? Fetching all agents is cheap (DB calls).
        # Reuse the logic from stats_page?
        
        # Fetch verified agents map
        agents_response = supabase.table('agents').select('name, faction').execute()
        registry = {
            row['name'].lower().strip(): {
                'name': row['name'], 
                'faction': row.get('faction', 'Wanderer')
            } for row in agents_response.data
        }
        
        repo_name = os.environ.get('REPO_NAME')
        all_signals = get_repository_signals(repo_name, registry)
        
        # Filter for this agent's integrated (merged) signals
        integrated_articles = [
            s for s in all_signals 
            if s['agent'].lower() == agent_name.lower() and s['status'] == 'integrated'
        ]
        
        # Match signals to local issues by Title (Fuzzy)
        all_issues = get_all_issues()
        for s in integrated_articles:
             # Try simple title substring logic
            matched_issue = None
            for issue in all_issues:
                 if issue['title'].lower() in s['title'].lower() or s['title'].lower() in issue['title'].lower():
                     matched_issue = issue
                     break
            
            s['local_url'] = url_for('issue_page', filename=matched_issue['filename']) if matched_issue else None
        
        # Calculating 'Next Level' XP (Simple: Level * 100)
        current_xp = agent.get('xp', 0)
        current_level = agent.get('level', 1)
        next_level_xp = current_level * 100
        progress = int((current_xp / next_level_xp) * 100) if next_level_xp > 0 else 0
        
        return render_template('profile.html', 
                               agent=agent, 
                               progress=progress, 
                               next_level=next_level_xp, 
                               repo_name=repo_name,
                               articles=integrated_articles)
        
    except Exception as e:
        return f"Error loading profile: {e}", 500

if __name__ == '__main__':
    debug_mode = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    app.run(debug=debug_mode, port=5000)
# redeploy
